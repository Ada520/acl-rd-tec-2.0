<?xml version="1.0" standalone="yes"?>

<Paper uid="J02-4001">
<Title></Title>
<Section position="1" start_page="0" end_page="400" type="abstr">
<SectionTitle>
1. Introduction and Definitions
</SectionTitle>
<Paragraph position="0"> As the amount of on-line information increases, systems that can automatically summarize one or more documents become increasingly desirable. Recent research has investigated types of summaries, methods to create them, and methods to evaluate them. Several evaluation competitions (in the style of the National Institute of Standards and Technology's [NIST's] Text Retrieval Conference [TREC]) have helped determine baseline performance levels and provide a limited set of training material.</Paragraph>
<Paragraph position="1"> Frequent workshops and symposia reflect the ongoing interest of researchers around the world. The volume of papers edited by Mani and Maybury (1999) and a book (Mani 2001) provide good introductions to the state of the art in this rapidly evolving subfield.</Paragraph>
<Paragraph position="2"> A summary can be loosely defined as a text that is produced from one or more texts, that conveys important information in the original text(s), and that is no longer than half of the original text(s) and usually significantly less than that. Text here is used rather loosely and can refer to speech, multimedia documents, hypertext, etc.</Paragraph>
<Paragraph position="3"> The main goal of a summary is to present the main ideas in a document in less space. If all sentences in a text document were of equal importance, producing a summary would not be very effective, as any reduction in the size of a document would carry a proportional decrease in its informativeness. Luckily, information content in a document appears in bursts, and one can therefore distinguish between more and less informative segments. Identifying the informative segments at the expense of the rest is the main challenge in summarization.</Paragraph>
<Paragraph position="4"> Of the many types of summary that have been identified (Borko and Bernier 1975; Cremmins 1996; Sparck Jones 1999; Hovy and Lin 1999), indicative summaries provide an idea of what the text is about without conveying specific content, and informative ones provide some shortened version of the content. Topic-oriented summaries concentrate on the reader's desired topic(s) of interest, whereas generic summaries reflect the author's point of view. Extracts are summaries created by reusing portions (words, sentences, etc.) of the input text verbatim, while abstracts are created by regenerating  Computational Linguistics Volume 28, Number 4 the extracted content. Extraction is the process of identifying important material in the text, abstraction the process of reformulating it in novel terms, fusion the process of combining extracted portions, and compression the process of squeezing out unimportant material. The need to maintain some degree of grammaticality and coherence plays a role in all four processes.</Paragraph>
<Paragraph position="5"> The obvious overlap of text summarization with information extraction, and connections from summarization to both automated question answering and natural language generation, suggest that summarization is actually a part of a larger picture. In fact, whereas early approaches drew more from information retrieval, more recent approaches draw from the natural language field. Natural language generation techniques have been adapted to work with typed textual phrases, in place of semantics, as input, and this allows researchers to experiment with approaches to abstraction. Techniques that have been developed for topic-oriented summaries are now being pushed further so that they can be applied to the production of long answers for the question-answering task. However, as the articles in this special issue show, domain-independent summarization has several specific, difficult aspects that make it a research topic in its own right.</Paragraph>
</Section>
</Paper>

