<?xml version="1.0" standalone="yes"?>

<Paper uid="J02-3001">
<Title>Automatic Labeling of Semantic Roles</Title>
<Section position="2" start_page="0" end_page="247" type="abstr">
<SectionTitle>
1. Introduction
</SectionTitle>
<Paragraph position="0"> Recent years have been exhilarating ones for natural language understanding. The excitement and rapid advances that had characterized other language-processing tasks such as speech recognition, part-of-speech tagging, and parsing have finally begun to appear in tasks in which understanding and semantics play a greater role. For example, there has been widespread commercial deployment of simple speech-based natural language understanding systems that answer questions about flight arrival times, give directions, report on bank balances, or perform simple financial transactions. More sophisticated research systems generate concise summaries of news articles, answer fact-based questions, and recognize complex semantic and dialogue structure.</Paragraph>
<Paragraph position="1"> But the challenges that lie ahead are still similar to the challenge that the field has faced since Winograd (1972): moving away from carefully hand-crafted, domain-dependent systems toward robustness and domain independence. This goal is not as  [?] Currently at Institute for Research in Cognitive Science, University of Pennsylvania, 3401 Walnut Street, Suite 400A, Philadelphia, PA 19104. E-mail: dgildea@cis.upenn.edu + Departments of Linguistics and Computer Science, University of Colorado, Boulder, CO 80309. E-mail:  Computational Linguistics Volume 28, Number 3 far away as it once was, thanks to the development of large semantic databases such as WordNet (Fellbaum 1998) and progress in domain-independent machine learning algorithms.</Paragraph>
<Paragraph position="2"> Current information extraction and dialogue understanding systems, however, are still based on domain-specific frame-and-slot templates. Systems for booking airplane information use domain-specific frames with slots like origcity, destcity,ordepart time (Stallard 2000). Systems for studying mergers and acquisitions use slots like products, relationship, jointventurecompany, and amount (Hobbs et al.</Paragraph>
<Paragraph position="3"> 1997). For natural language understanding tasks to proceed beyond these specific domains, we need semantic frames and semantic understanding systems that do not require a new set of slots for each new application domain.</Paragraph>
<Paragraph position="4"> In this article we describe a shallow semantic interpreter based on semantic roles that are less domain specific than toairport or jointventurecompany. These roles are defined at the level of semantic frames of the type introduced by Fillmore (1976), which describe abstract actions or relationships, along with their participants. For example, the Judgement frame contains roles like judge, evaluee, and reason, and the Statement frame contains roles like speaker, addressee, and message,as the following examples show:  tion. For example, a semantic role parse would allow a system to realize that the ruling that is the direct object of change in (3) plays the same Theme role as the ruling that is the subject of change in (4): (3) The canvassing board changed its ruling on Wednesday.</Paragraph>
<Paragraph position="5"> (4) The ruling changed because of the protests.</Paragraph>
<Paragraph position="6">  The fact that semantic roles are defined at the frame level means, for example, that the verbs send and receive would share the semantic roles (sender, recipient, goods, etc.) defined with respect to a common Transfer frame. Such common frames might allow a question-answering system to take a question like (5) and discover that (6) is relevant in constructing an answer to the question:  (5) Which party sent absentee ballots to voters? (6) Both Democratic and Republican voters received absentee ballots from  their party.</Paragraph>
<Paragraph position="7"> This shallow semantic level of interpretation has additional uses outside of generalizing information extraction, question answering, and semantic dialogue systems. One such application is in word sense disambiguation, where the roles associated with a word can be cues to its sense. For example, Lapata and Brew (1999) and others have shown that the different syntactic subcategorization frames of a verb such as serve can be used to help disambiguate a particular instance of the word. Adding semantic role subcategorization information to this syntactic information could extend this idea to  Gildea and Jurafsky Automatic Labeling of Semantic Roles use richer semantic knowledge. Semantic roles could also act as an important intermediate representation in statistical machine translation or automatic text summarization and in the emerging field of text data mining (TDM) (Hearst 1999). Finally, incorporating semantic roles into probabilistic models of language may eventually yield more accurate parsers and better language models for speech recognition.</Paragraph>
<Paragraph position="8"> This article describes an algorithm for identifying the semantic roles filled by constituents in a sentence. We apply statistical techniques that have been successful for the related problems of syntactic parsing, part-of-speech tagging, and word sense disambiguation, including probabilistic parsing and statistical classification. Our statistical algorithms are trained on a hand-labeled data set: the FrameNet database (Baker, Fillmore, and Lowe 1998; Johnson et al. 2001). The FrameNet database defines a tag set of semantic roles called frame elements and included, at the time of our experiments, roughly 50,000 sentences from the British National Corpus hand-labeled with these frame elements.</Paragraph>
<Paragraph position="9"> This article presents our system in stages, beginning in Section 2 with a more detailed description of the data and the set of frame elements or semantic roles used. We then introduce (in Section 3) the statistical classification technique used and examine in turn the knowledge sources of which our system makes use. Section 4 describes the basic syntactic and lexical features used by our system, which are derived from a Penn Treebank-style parse of individual sentences to be analyzed. We break our task into two subproblems: finding the relevant sentence constituents (deferred until Section 5), and giving them the correct semantic labels (Sections 4.2 and 4.3). Section 6 adds higher-level semantic knowledge to the system, attempting to model the selectional restrictions on role fillers not directly captured by lexical statistics. We compare hand-built and automatically derived resources for providing this information. Section 7 examines techniques for adding knowledge about systematic alternations in verb argument structure with sentence-level features. We combine syntactic parsing and semantic role identification into a single probability model in Section 8. Section 9 addresses the question of generalizing statistics from one target predicate to another, beginning with a look at domain-independent thematic roles in Section 9.1. Finally we draw conclusions and discuss future directions in Section 10.</Paragraph>
</Section>
</Paper>

