<?xml version="1.0" standalone="yes"?>

<Paper uid="W02-1008">
<Title>Combining Sample Selection and Error-Driven Pruning for Machine Learning of Coreference Rules</Title>
<Section position="1" start_page="0" end_page="0" type="abstr">
<SectionTitle>
Abstract
</SectionTitle>
<Paragraph position="0"> Most machine learning solutions to noun phrase coreference resolution recast the problem as a classification task. We examine three potential problems with this reformulation, namely, skewed class distributions, the inclusion of &amp;quot;hard&amp;quot; training instances, and the loss of transitivity inherent in the original coreference relation.</Paragraph>
<Paragraph position="1"> We show how these problems can be handled via intelligent sample selection and error-driven pruning of classification rulesets. The resulting system achieves an F-measure of 69.5 and 63.4 on the MUC-6 and MUC-7 coreference resolution data sets, respectively, surpassing the performance of the best MUC-6 and MUC-7 coreference systems. In particular, the system outperforms the best-performing learning-based coreference system to date.</Paragraph>
</Section>
</Paper>

