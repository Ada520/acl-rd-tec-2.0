<?xml version="1.0" standalone="yes"?>

<Paper uid="J82-3003">
<Title>Using Semantics in Non-Context-Free Parsing of Montague Grammar 1</Title>
<Section position="2" start_page="0" end_page="0" type="abstr">
<SectionTitle>
1. Equivalence Parsing
Ambiguity
</SectionTitle>
<Paragraph position="0"> Ambiguity in Montague grammar is measured by the number of different meanings. In this view syntactic structure is of no interest in its own right, but only as a vehicle for mapping semantics. Syntactic ambiguity does not directly correspond to semantic ambiguity, and there may be many parses with the same semantic interpretation. Further, sentences with scope ambiguity, such as A man loves every woman, require more than one parse, because the syntactic derivation determines quantifier scope.</Paragraph>
<Paragraph position="1"> In PTQ there is infinite syntactic ambiguity arising from three sources: alphabetic variants of variables, variable for variable substitutions, and vacuous variable substitution. However, these semantically unnecessary constructs can be eliminated, so that the set of syntactic sources for any sentence is finite, and a parser that finds the full set is possible. (This corresponds to the &amp;quot;variable principle&amp;quot; enunciated by Janssen 1980 and used by Landsbergen 1980.) This approach was the basis of our earlier PTQ parser (Friedman and Warren 1978).</Paragraph>
<Paragraph position="2"> However, even with these reductions the number of remaining parses for a sentence of reasonable complexity is still large compared to the number of non-equivalent translations. In the directed process approach this is treated by first finding all the parses, next finding for each parse a reduced translation, and then finally obtaining the set of reduced translations.</Paragraph>
<Paragraph position="3"> Each reduced translation may, but does not necessarily, represent a different sentence meaning. No meanings are lost. Further reductions of the set of translations would be possible, but the undecidability of logical equivalence precludes algorithmic reduction to a minimal set.</Paragraph>
<Paragraph position="4"> The ATN Program In the underlying parser the grammar is expressed as an augmented transition network (ATN) (Woods 1973). Both the syntactic and the semantic parsers use this same ATN. The main difficulty in construct124 American Journal of Computational Linguistics, Volume 8, Number 3-4, July-December 1982 David Scott Warren and Joyce Friedman Using Semantics in Non-Context-Free Parsing ing the ATN was, as usual, the non-context-free aspects of the grammar, in particular the incorporation of a treatment of substitution rules and variables. The grammar given in PTQ generates infinitely many derivations for each sentence. All but finitely many of these are unnecessary variations on variables and were eliminated in the construction of the ATN. The ATN represents only the reduced set of structures, and must therefore be more complex.</Paragraph>
<Section position="1" start_page="0" end_page="0" type="sub_section">
<SectionTitle>
Equivalence Testing
</SectionTitle>
<Paragraph position="0"> In order to say what we mean by semantic equivalence parsing, we use Harel's 1979 notion of execution method for nondeterministic programs. An execution method is a deterministic procedure for finding the possible execution paths through a nondeterministic program given an input. For an ATN, these execution paths correspond to different parses. Viewing parsing in this way, the only difference between the usual syntactic parsing and semantic equivalence parsing is a difference in the execution method. As will be seen, semantic equivalence parsing uses semantic tests as part of the execution method.</Paragraph>
<Paragraph position="1"> We call the execution method we use to process a general ATN equivalence parsing (Warren 1979).</Paragraph>
<Paragraph position="2"> Equivalence parsing is based on a recall table. The recall table is a set of buckets used to organize and hold partial syntactic structures while larger ones are constructed. Equivalence parsing can be viewed as processing an input sentence and the ATN to define and fill in the buckets of the recall table. The use of the recall table reduces the amount of redundant processing in parsing a sentence. Syntactic structures found along one execution path through the ATN need not be reconstructed but can be directly retrieved from the recall table and used on other paths. The recall table is a generalization of the familiar well-formed substring table (WFST) to arbitrary programs that contain procedure calls. Use of the WFST in ATN parsing is noted in Woods 1973 and Bates 1978.</Paragraph>
<Paragraph position="3"> Bates observes that the WFST is complicated by the HOLDs and SENDRs in the ATN. These are the ATN actions that correspond to parameter passing in procedures and are required in the ATN for PTQ to correctly treat the substitution rules.</Paragraph>
<Paragraph position="4"> In the Woods system the WFST is viewed as a possible optimization, to be turned on when it improves parsing efficiency. In our system the recall table is an intrinsic part of the parsing algorithm. Because any ATN that naturally represents PTQ must contain left recursion, the usual depth-first (or breadth-first or best-first) ATN parsing algorithm would go into an infinite loop when trying to find all the parses of any sentence. The use of the recall table in equivalence parsing handles left-recursive ATNs without special consideration (Warren 1981). As a result there is no need to rewrite the grammar to eliminate left-recursive rules as is usually necessary.</Paragraph>
<Paragraph position="5"> In a general nondeterministic program, a bucket in the recall table corresponds to a particular subroutine and a set of values for the calling parameters and return parameters. For an ATN a bucket is indexed by a triple: (1) a grammatical category, that is, a subnet to which a PUSH is made, (2) the contents of the SENDR registers at the PUSH and the current string, and (3) the contents of the LIFTR registers at the POP and the then-current string. A bucket contains the members of an equivalence class of syntactic structures; precisely what they are depends on what type of equivalence is being used.</Paragraph>
<Paragraph position="6"> What makes equivalence parsing applicable to non-context-free grammars is that its buckets are more general than the cells in the standard tabular context-free algorithms. In the C-K-Y algorithm (Kasami 1965), for example, a cell is indexed only by the starting position and the length of the parsed segment, i.e., the current string at PUSH and POP. The cell contents are nonterminals. In our case all three are part of the bucket index, which also includes SENDR and LIFTR register values. The bucket contents are equivalence classes of structures.</Paragraph>
</Section>
<Section position="2" start_page="0" end_page="0" type="sub_section">
<SectionTitle>
Sentence Recognition
</SectionTitle>
<Paragraph position="0"> For sentence recognition all parses are equivalent.</Paragraph>
<Paragraph position="1"> So it is enough to determine, for each bucket of the recall table, whether or not it is empty. A sentence is in the language if the bucket corresponding to the sentence category (with empty SENDR registers and full string, and empty LIFTR registers and null string) is nonempty. The particular forms of the syntactic structures in the bucket are irrelevant; the contents of the buckets are only a superfluous record of the specific syntactic structures. The syntactic structure is never tested and so does not affect the flow of control. Thus which buckets are nonempty depends only on what other buckets are nonempty and not on what those other buckets contain. For sentence recognition, when the execution method constructs a new member of a bucket that is already nonempty, it may or may not add the new substructure, but it does not need to use it to construct any larger syntactic structures. This is because the earlier member has already verified this bucket as nonempty. Therefore this fact is already known and is already being used to determine the nonemptiness of other buckets. To find all parses, however, equivalence parsing does use all members of each bucket to construct larger structures.</Paragraph>
<Paragraph position="2"> It would be possible first to do recognition and determine all the nonempty buckets in the recall table, and then to go back and take all variants of one single parse that can be obtained by replacing any substructure.by another substructure from the same bucket. American Journal of Computational Linguistics, Volume 8, Number 3-4, July-December 1982 125 David Scott Warren and Joyce Friedman Using Semantics in Non-Context-Free Parsing This is essentially how the context-free parsing algorithms constructed from the tabular recognition methods work. This is not how the equivalence parsing algorithm works. When it obtains a substructure, it immediately tries to use it to construct larger structures. null The difference described above between sentence recognition and sentence parsing is a difference only in the execution methods used to execute the ATN and not in the ATN itself. This difference is in the test for equivalence of bucket contents. In sentence recognition any two syntactic structures in a bucket are equivalent since we only care whether or not the substring can be parsed to the given category. At the other extreme, in finding all parses, two entries are equivalent only if they are the identical structure. For most reasonable ATNs, including our ATN for PTQ, this would not happen; distinct paths lead to distinct structures. null Semantic parsing is obtained by againmodifying only the equivalence test used in the execution method to test bucket contents. For semantic parsing two entries are equivalent if their logical translations, after logical reduction and extensionalization, are identical to within change of bound variable.</Paragraph>
</Section>
<Section position="3" start_page="0" end_page="0" type="sub_section">
<SectionTitle>
Small Grammar
</SectionTitle>
<Paragraph position="0"> For our examples, we introduce in Figure 1 a small subnet of the ATN for PTQ. Arcs with fully capitalized labels are PUSH arcs; those with lower case labels are CAT arcs. Structure-building operations are indicated in parentheses. This net implements just three rules of PTQ. Rule $4 forms a sentence by concatenating a term phrase and an intransitive verb phrase; Sll conjoins two sentences, and S14,i substitutes a term phrase for the syntactic variable he i in a sentence. $4 and Sll are context-free rules; S14,i is one of the substitution rules that make the grammar non-context-free and is basic to the handling of quantifiers, pronouns, and antecedents. The ATN handles the substitution by using a LIFTR to carry the variable-binding information. The LIFTR is not used for the context-free rules.</Paragraph>
<Paragraph position="1">  The first example is the sentence Bill walks. This sentence has the obvious parse using only the context-free rule $4. It also has the parse using the substitution rule. We will carry through the details of its parse to show how this substitution rule is treated in the parsing process.</Paragraph>
<Paragraph position="2"> In the trace PUSHes and POPs in the syntactic analysis of this sentence are shown. The entries are in chronological order. The PUSHes are numbered sequentially for identification. The PUSH number uniquely determines a) the category to which the PUSH is made, b) the remainder of the sentence being parsed at the time of the PUSH, and c) the contents of the SENDR registers at the time of the PUSH, called the PUSH environment. At each POP a bucket and an element in that bucket are returned. The bucket name at a POP is made up of the corresponding PUSH number, the remaining input string, and the contents of the LIFTR registers, which are called the POP environment. The element in the bucket is the tree that is returned. For brevity we use in the trace only the first letters of the words in the sentence; for example, Bill walks becomes Bw.</Paragraph>
<Paragraph position="3">  parse fails, and the execution method backs up to seek another return from PUSH 1.\] 1 e null (S14,0 Bill ($4 he0 walk)) \[This is another element in bucket 1-e-null; it is a successful parse so it is printed out. Execution continues but there are no more parses of the sentence.\]  In this trace bucket t-e-null is the only bucket with more than one entry. The execution method was syntactic parsing, so each of the two entries was returned and printed out. For recognition, these two entries in the bucket would be considered the same and the second would not have been POPped. Instead of continuing the computation up in the subnet from which the PUSH was made, this path would be made to fail and the execution method would back up. For semantic equivalence parsing, the bucket contents throughout would not be the syntax trees, but would instead be their reduced extensionalized logical formulas. (Each such logical formula represents the equivalence class of the syntactic structures that correspond to the formula.) For example, bucket 2-w-null would contain ~,Pp{Ab} and bucket 3-c-null would contain walk'. The first entry to bucket 1-E-null would be the formula for ($4 Bill walk), that is, walk.'(b). The entry to bucket 1-e-null on the last line of the trace American Journal of Computational Linguistics, Volume 8, Number 3-4, July-December 1982 127 David Scott Warren and Joyce Friedman Using Semantics in Non-Context-Free Parsing would be the formula for (S14,0 Bill ($4 he0 walk)), which is also walk.'(b). Therefore, this second entry would not be POPped.</Paragraph>
<Paragraph position="4"> Buckets also serve to reduce the amount of repeated computation. Suppose we have a second PUSH to the same category with the same string and environment as an earlier PUSH. The buckets resulting from this new PUSH would come out to be the same as the buckets from the earlier PUSH. Therefore the buckets need not be recomputed; the results of the earlier buckets can be used directly. This is called a &amp;quot;FAKEPUSH&amp;quot; because we don't actually do the PUSH to continue through the invoked subnet but simply do a &amp;quot;FAKEPOP&amp;quot; using the contents of the previously computed buckets.</Paragraph>
<Paragraph position="5"> Consider, as an example of FAKEPOP, the partial trace of the syntactic parse of the sentence Bill walks and Mary runs (or Bw&amp;Mr for short). The initial part of this trace, through step 4, is essentially the same as the trace above for the shorter sentence Bill walks.</Paragraph>
<Paragraph position="6"> Trace of Bill walks and Mary runs  \[Again a tree has been returned to the top level, but it does not span the whole string, nor is the returned environment null, so we fail.\] 1 &amp;Mr null (S14,0 Bill ($4 he0 walk)) \[Again we are the top level; again we do not span the whole string, so again we fail.\]</Paragraph>
</Section>
</Section>
</Paper>

