<?xml version="1.0" standalone="yes"?>

<Paper uid="P82-1022">
<Title>THEMES FROM 1972</Title>
<Section position="1" start_page="0" end_page="0" type="abstr">
<SectionTitle>
THEMES FROM 1972
</SectionTitle>
<Paragraph position="0"> Although 1972 was the year that Winograd published his now classic natural language Study of the blocks world, that fact had not yet penetrated to the ACL. At that time people with AI computational interests were strictly in a minority in the association and it was a radical move to appoint Roger Schank as program chairman for the year's meeting. That was also the year that we didn't have a presidential banquet, and my &amp;quot;speech&amp;quot; was a few informal remarks at the roadhouse restaurant somewhere in North Carolina reassuring a doubtful few members that computational understanding of natural language was certainly progressing and that applied natural language systems were distinctly feasible.</Paragraph>
<Paragraph position="1"> My own perceptions of the state of computational linguistics during that period were given in &amp;quot;On Seeing the Elephant&amp;quot; in the Finite String, March-Aprll 1972. I saw it as a time of confusion, of competition among structuralists, transformationallsts, and the new breed of computernlks. &amp;quot;On Seeing the Elephant&amp;quot; was a restatement of the old Sufi parable that suggested that we each perceived only isolated parts of our science.</Paragraph>
<Paragraph position="2"> That was the period during which Jonathan Slocum and I were concerned with using Augmented Transition Networks to generate coherent English from semantic networks. That llne of research was originated by the first President of the Association, Victor Yngve, who in 1960 had published descriptions of algorithms for using a phrase structure grammar to generate syntactically well-formed nonsense sentences \[Yngve 1960\].</Paragraph>
<Paragraph position="3"> Sheldon Klein and I about 1962-1964 were fascinated by the technique and generalized it to a method for controlling the sense of what was generated by respecting the semantic dependencies of words as they occurred in text. Yngve's work was truly seminal and it continued to inspire Sheldon for years as he developed method after method for generating detective stories and now operas. I, too, with various students continued to explore the generation side of language, most recently with Correlra \[1979\], using a form of story tree to construct stories and their summaries. No matter that Meehan found better methods and Bill Mann and his colleagues continue to improve on the techniques. The use of a phrase structure grammar to control the sequence in which sentences and words are p~oduced remains quite as fascinating as its use in translatln~ sentences to representations of meaning.</Paragraph>
<Paragraph position="4"> It is possible to communicate the technique for controlled generation of text in Just a few paragraphs, so in dedication to Yngve, Klein, and i00 the many others of the discipline who share our fascination with generation of meaningful language, the following description is presented. The last two lines of Keats&amp;quot; &amp;quot;Ode to a Grecian Urn&amp;quot; are: Beauty is truth, truth beauty, that is all Ye know on earth and all ye need to know.</Paragraph>
<Paragraph position="5"> To form semantically controlled variations on this verse we can create substitution classes as below:  and llne rules similar to phrase structure forms. (I think of the couplet as a three llne verse.) \[KLINEI beauty is truth -- truth beauty\] \[KLINE2 (that is all) ye know (on earth)\] \[KLINE3 (that is all) ye (need to) know\] Each KLINEi rewrites as a conjunction terms, e.g., KLINEI --&gt; beauty + is + truth ... + beauty.</Paragraph>
<Paragraph position="6"> of The line rules are composed of terms such as &amp;quot;beauty&amp;quot;, &amp;quot;that is all&amp;quot;, etc., that begin SCLASS predications, and of terminals such as &amp;quot;is&amp;quot; and &amp;quot;-&amp;quot; that do not. Poem and verse can also be defined as rules: \[POEM title verse verse ... verse\] \[TITLE (Variation on Keats&amp;quot; Truth is Beauty)\] \[VERSE klinel kllne2 kllne3\] Actually it is more convenient to define these latter three elements as program to control choice of grammar, spacing, and number of verses. In either case, a POEM is a TITLE followed by VERSEs, an~ ~ VERSE is three lines each composed of terminals that occur in a KLINE or of selections from the matching substitution class.</Paragraph>
<Paragraph position="7"> Only one other program element is required: a random selection function to pseudo-randomly choose an element from a substitution class and to record that element as chosen:  content of an SCLASS rule in the list (FIRST.REMDR); if a choice for the term has previously been made in the verse, CHOICE is taken from the predicate, (CHOSEN FIRST CHOICE). If not, RANDOM* selects an element and records it as CHOSEN. When a verse is begun, any existing CHOSEN predicates are deleted.</Paragraph>
<Paragraph position="8"> This is a procedural logic program with lists in dot notation and variables marked using the underscore. It is presented to give a sense of how the program appears in Dan Chester's LISP version of PROLOG. The rest of the program follows the poem, verse, and Keats-LINE rules given above.</Paragraph>
<Paragraph position="9"> The program is called by (POGEN KEATS 4), KEATS selecting the grammar and 4 signifying the number of verses. A couple of recordings of its behavior appear below.</Paragraph>
<Paragraph position="10">  Perhaps these verses might best be characterized as those Keats wisely rejected.</Paragraph>
<Paragraph position="11"> Nevertheless our robot-poet demonstrates the effectiveness of phrase structure organization and substitution classes for selecting and ordering actions.</Paragraph>
<Paragraph position="12"> The ideas of Pogen led to related methods for creating paraphrases, answering questions, and translating between languages. The principle of phrase structure organization has permeated our NL efforts and found a particularly friendly environment in procedural logic where Chester and I \[1982\] show that the same grammar that translates English strings into semantic representations can serve to translate the representations into English strings. This result, confirming an earlier finding by Heldorn, greatly simplifies the linguistic programming requirements for NL translation and text questioning systems.</Paragraph>
<Paragraph position="13"> Since 1972 the computational linguistics world has changed much. Today AI and Logic interests tend to overshadow linguistic approaches to language. But despite all the complexities in translating between NL constituents and computational representations, augmented phrase structure grammars provide a general and effective means to guide the flow of computation.</Paragraph>
</Section>
</Paper>

