<?xml version="1.0" standalone="yes"?>

<Paper uid="C90-3086">
<Title>amp;quot;The first million is hardest to get&amp;quot;: Building a Large Tagged Corpus as Automatically as Possible</Title>
<Section position="2" start_page="0" end_page="0" type="abstr">
<SectionTitle>
400 I
</SectionTitle>
<Paragraph position="0"> valuable basis for many kinds of linguistic investigations, but the methods developed and refined in building the corpus will be quite as important as an output, as they can be used for building the even larger corpora that will be necessary for certain kinds of largedeg scale linguistic analysis. We hope to be able to take a considerable step towards a fully automatized tagging of unrestricted text, but .. as noted in the heading and as many multimillionaires have also noted - the first million is the hardest to get.</Paragraph>
<Paragraph position="1"> Along with the methods for building the corpus, we will also develop a set of simple tools for using it: programs for search on different levels, for excerption and building of concordances, for sorting according to different criteria, and, not least important, for the addition of the user's own tags in a standardized and compatible format. The resulting corpus and the 'tool-kit' for using it will be made available to other researchers in a tor~nat suitable for different kinds of personal computersdeg This will, hopefully, facilitate and ~hereby increase the research on modern written Swedish.</Paragraph>
<Paragraph position="2"> We must however admit that we do not do Ihis out of an unselfish concern for others. On the contrary our original impetus was a vmy selfish need to be able to test and develop our own models and ideas on a large scale. This is where the fun really starts, but as most of this i:s so far not implemented, or only to a small degree, I will not say anything more about it here, but will return briefly to some of it in the section about expected problems and expected results.</Paragraph>
<Paragraph position="3"> 2. To build a large corpus in a short time, we will have to rely almost entirely on mater.ial that is computer-readable from the begin-~dng, i.e. mostly material that is typeset on computers. This will bring us into a jungle of non-linguistic but time-consuming problems: getting access to data tapes, loading them to oar own computers, converting between different formats and different character conw~ntions, deciding which typographic features can be discarded and which contain informao tion that nmst be kept, deciding how to treat pictures, figures, and diagrams, etc.</Paragraph>
<Paragraph position="4"> On top of this, we have the questions of coverage and representativity. If we could just take any kind of computer readable text until we get a large enough corpus everything would be so much easier, but now we have to find texts from many different genres and, consequently, from many different sources.</Paragraph>
<Paragraph position="5"> This will multiply problems of the type mentioned in the preceding paragraph, but it will also force us to cope with copyright restrictions. Our wish to cover different kinds of text genres, including fiction, in combination with our wish to have texts that are coherent wholes and to make all the tagged texts generally available for research purposes, will here bring us in conflict with copyright regulations.</Paragraph>
<Paragraph position="6"> If necessm3,, we will change the proportions between different genres rather than have parts of the corpus not generally available.</Paragraph>
<Paragraph position="7"> The problems sketched in the last two paragraphs are certainly of importance but I will not discuss them here. Rather, I will describe some of the truly linguistic matters we have to deal with and, in the last section, proceed to show possible solutions to some of them.</Paragraph>
<Paragraph position="8"> The best basis for the kind of tagging we want to do is a computerized lexicon that covers as much as possible of the vocabulary of unrestricted text, and that gives as much as possible of the morpho-syntactic information we want to represent. In this respect, we are extremely lucky in that we can have access to three different computerized lexica designed for analysis of Swedish word forms. By the kind permission of the respective lexicon builders, we can test their models and pick the one that suits our special purposes best. The three lexica are the TWOL:lexicon from the University of Helsinki (Karlsson forthcoming), the lexicon from Chalmers University of Technology, Gothenburg, that was originally designed for speech synthesis (Hedelin et al.</Paragraph>
<Paragraph position="9"> 1989), and the morphological analyzer developed within the LPS-project at the university of Gothenburg (S~gvall 1989).</Paragraph>
<Paragraph position="10"> This possibility of lexicon look up brings the project a great leap forward, but, alas, with much left to be done. According to statistics (All6n 1970, p. xxv), almost 65% of the word tokens in Swedish texts are ambiguous. (The</Paragraph>
<Paragraph position="12"> corresponding figures for English and Finnish are 45% and 15%, respectively. Cf. DeRose 1988, Karlsson forthcoming.)The large figure for Swedish may seem astonishing, but a careful manual check of the output from the look up of 2,000 running words in the Helsinki TWOL-lexicon showed that at least 55 % of all words were ambiguous in any way, with an average of 2.6 readings of each ambiguous word.</Paragraph>
<Paragraph position="13"> Ambiguities can be between lemmas (word types) from different word classes, different lemmas within the same word class, and different inflectional forms within the same lemma. A typical example would be the word 'glada' that can either be a noun, the name of a bird, or an adjective, meaning 'happy'. As an adjective, the word is manyways ambiguous between a singular definite reading that can be either neuter or common gender, and a plural reading that can be definite or indefinite and in either case belong to either gender. Ambiguity between different lemmas within the same word class is a less common type. It can be seen in a word (token) like 'svans' that can either mean 'tail' or be the genitive form of 'swan'. We have not counted as ambiguities polysemous words with identical inflectional pattern, like 'krona', which is either 'a crown' or the Swedish currency unit. All these ambiguities have to be sorted out in the disambiguation process.</Paragraph>
<Paragraph position="14"> In this disambiguation, we will mainly use robust methods that for every ambiguous situation will come up with a best possible solution. (Cf. K~illgren 1984a,b,1990, Brodda 1983.) This will partly be based on another important step in the process, namely the construction of constituents, in particular noun phrases and prepositional phrases (Church 1988, Kfillgren 1984c), and partly on a more general algorithm that for pairs or longer sequences of tags calculates the relative probability of alternative tag assignments. The principles behind such algorithms are known, but they have never been tried on Swedish material (DeRose 1988, Marshall 1987, Eeg-Olofsson 1985).</Paragraph>
<Paragraph position="15"> An indispensable step in the disambiguation process is the assignment of clause boundaries, which presupposes established constituents at the same time as it forms an important basis for disambiguating chains of tags. Methods for this are being tested out on Swedish material (Ejerhed 1989). Given this, it might be possible to check the valency structure of predicates, to decide subject and direct object and, more difficult, to decide the role of prepositional phrases in relation to the finite verb.</Paragraph>
<Paragraph position="16"> In all the above steps, we will use robust methods that can give a straightforward, 'flat' analysis of the surface sentences. The final output will be carefully proofread and can then function as a corpus for empirical research, a test-bench for theoretical linguists' models, and a training material in the development of stochastic methods of analysis (cf. K/illgren 1988).</Paragraph>
<Paragraph position="17"> 3. Several of the programs needed in the project already exist, at least as running prototypes, and can be demonstrated. Among those are a system for converting from the explicit tags of the TWOL- lexicon to our more condensed and sometimes different tags, as well as from our condensed tags to an explicit transcription of them. (Our tags sometimes have a finer subclassification than is at present the case with the TWOL-tags.) In connection with this, we are willing to discuss our set of tags, which, by necessity, is a compromise between what is wanted and what can be achieved with a reasonable amount of effort.</Paragraph>
<Paragraph position="18"> Our technique of using temporary, ambiguous tags to postpone decisions in non-deterministic situations will also be discussed. Below are the suggested tags of the word 'hoppa' ('to jump' or 'jump!') given as an example.</Paragraph>
<Paragraph position="19"> Output from TWOL-lexicon: hoppa &amp;quot;V IMWINF&amp;quot; Condensed temporary tag: Vlla &lt; hoppa &gt; where: V = finite verb, 1 = lexicalverb (i.e. not copula, modal, or auxiliary), 1 = imperative or infinitive, a = active, belonging to the lemma hoppa 402 3 Data driven disambiguation procedures can then be applied. The disambiguation will be triggered and governed by the '1', in this case directed to look for, e.g., a preceding auxiliary verb or infinitive marker signalling infinitive as opposed to the possible syntactic environments of imperatives. Assuming that the word appears in a context where it functions as an infinitive, the output will be 'Vlia &lt; hoppa &gt; 'else 'Vlma &lt; hoppa &gt; ', but even before this decision is reached, the information that the word is not in any of the other tenses can be used by other disambiguation procedures.</Paragraph>
<Paragraph position="20"> For the disambiguation, we have started on a first prototype of a 'learning' program, i.e. the program can be trained to make a best possible choice in different situations, where the situations are sequences of ambiguous tags (Karlgren 1989). It is a Prolog implementation of principles presented in Kiillgren (1984b).</Paragraph>
<Paragraph position="21"> For :further analysis of the corpus we have a program that identifies subject and direct and indirect object in simple and complex sentences. It is based on an algorithm that has been tested manually (Kiillgren 1987) with good results, and has now been implemented as an expert system with a set of if...then-rules (Magnberg 1990). The program presupposes that word class disambiguation, constituent construction, and clause boundary identification has been carried out. It will be demonstrated at Coling.</Paragraph>
<Paragraph position="22"> To facilitate the use of the corpus also for non-computational linguists, we plan to supply the completed corpus with a packet of tools. As an example of such tools, a version of the Beta system that is especially designed for making excerptions and concordances on personal computers will be demonstrated (Brodda 1990a, b).</Paragraph>
</Section>
</Paper>

