<?xml version="1.0" standalone="yes"?>

<Paper uid="P95-1018">
<Title>Getting the message across in RST-based text</Title>
<Section position="2" start_page="0" end_page="130" type="abstr">
<SectionTitle>
Abstract
</SectionTitle>
<Paragraph position="0"> Our goal is to identify the features that predict cue selection and placement in order to devise strategies for automatic text generation. Much previous work in this area has relied on ad hoc methods. Our coding scheme for the exhaustive analysis of discourse allows a systematic evaluation and refinement of hypotheses concerning cues.</Paragraph>
<Paragraph position="1"> We report two results based on this analysis: a comparison of the distribution of Sn~CE and BECAUSE in our corpus, and the impact of embeddedness on cue selection.</Paragraph>
<Paragraph position="2"> Discourse cues play a crucial role in many discourse processing tasks, including plan recognition (Litman and Allen, 1987), anaphora resolution (Gross and Sidner, 1986), and generation of coherent multisentential texts (Elhadad and McKeown, 1990; Roesner and Stede, 1992; Scott and de Souza, 1990; Zukerman, 1990). Cues are words or phrases such as BECAUSE, FIRST, ALTHOUGH and ALSO that mark structural and semantic relationships between discourse entities. While some specific issues concerning cue usage have been resolved (e.g., the disambiguation of discourse and sentential cues (Hirschberg and Litman, 1993)), our concern is to identify general strategies of cue selection and placement that can be implemented for automatic text generation. Relevant research in reading comprehension presents a mixed picture (Goldman and Murray, 1992; Lorch, 1989), suggesting that felicitous use of cues improves comprehension and recall, but that indiscriminate use of cues may have detrimental effects on recall (Millis et al., 1993) and that the benefit of cues may depend on the subjects' reading skill and level of domain knowledge (McNamara et al., In press). However, interpreting the research is problematic because the manipulation of cues both within and across studies has been very unsystematic (Lorch, 1989). While Knott and Dale (1994) use systematic manipulation to identify functional categories of cues, their method does not provide the description of those functions needed for text generation.</Paragraph>
<Paragraph position="3"> For the study described here, we developed a coding scheme that supports an exhaustive analysis of a discourse. Our coding scheme, which we call Relational Discouse Analysis (RDA), synthesizes two accounts of discourse structure (Gross and Sidner, 1986; Mann and Thompson, 1988) that have often been viewed as incompatible. We have applied RDA to our corpus of tutorial explanations, producing an exhaustive analysis of each explanation. By doing such an extensive analysis and representing the results in a database, we are able to identify patterns of cue selection and placement in terms of multiple factors including segment structure and semantic relations. For each cue, we determine the best description of its distribution in the corpus. Further, we are able to formulate and verify more general patterns about the distribution of types of cues in the corpus. The corpus study is part of a methodology for identifying the factors that influence effective cue selection and placement. Our analysis scheme is co-ordinated with a system for automatic generation of texts. Due to this coordination, the results of our analyses of &amp;quot;good texts&amp;quot; can be used as rules that are implemented in the generation system. In turn, texts produced by the generation system provide a means for evaluation and further refinement of our rules for cue selection and placement. Our ultimate goal is to provide a text generation component that can be used in a variety of application systems. In addition, the text generator will provide a tool for the systematic construction of materials for reading comprehension experiments.</Paragraph>
<Paragraph position="4"> The study is part of a project to improve the explanation component of a computer system that trains avionics technicians to troubleshoot complex electronic circuitry. The tutoring system gives the student a troubleshooting problem to solve, allows the student to solve the problem with minima\] tutor interaction, and then engages the student in a postproblem critiquing session. During this session, the system replays the student's solution step by step, pointing out good aspects of the solution as well as ways in which the solution could be improved.</Paragraph>
<Paragraph position="5">  To determine how to build an automated explanation component, we collected protocols of 3 human expert tutors providing explanations during the critiquing session. Because the explanation component we are building interacts with users via text and menus, the student and human tutor were required to communicate in written form. In addition, in order to study effective explanation, we chose experts who were rated as excellent tutors by their peers, students, and superiors.</Paragraph>
</Section>
</Paper>

