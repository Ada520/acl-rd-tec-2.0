<?xml version="1.0" standalone="yes"?>

<Paper uid="P86-1001">
<Title>TUTORIAL ABSTRACTS</Title>
<Section position="1" start_page="0" end_page="0" type="abstr">
<SectionTitle>
TUTORIAL ABSTRACTS
</SectionTitle>
<Paragraph position="0"> This tutorial provides a general overview of computational linguistics. Topics to be considered include the components of a natural language processing system; syntax analysis (including context-free grammars, augmented context-free grammars, grammatical constraints, and sources of syntactic ambiguity); semantic analysis (including meaning representation, semantic constraints, quantifier analysis); and discourse analysis (identifying implicit information, establishing text coherence, frames, and scripts). Examples will be drawn from various application areas, including database interface and text analysis.</Paragraph>
<Section position="1" start_page="0" end_page="0" type="sub_section">
<SectionTitle>
Natural Language Generation
Kathleen McKeown, Columbia University
</SectionTitle>
<Paragraph position="0"> In this tutorial, we will begin by identifying the types of decisions involved in language generation and how they differ from problems in the interpretation of natural language.</Paragraph>
<Paragraph position="1"> Several techniques that have been used for &amp;quot;surface&amp;quot; generation (i.e., determining the syntactic structure and vocabulary of the generated text) will be examined, including grammars, dictionaries, and templates. From there, we will move on to other problems in language generation, including how the system can decide what to say in a given situation and how it can order the information for inclusion in a text. Here we will study the constraints that have been used for these decisions in domains such as expert systems, database systems, scene description, and problem solving. We will also look at the interaction between conceptual decisions such as these and decisions in surface generation, considering approaches that propose an integrated solution.</Paragraph>
<Paragraph position="2"> Structuring the Lexicon Robert Ingria, BBN Laboratories Incorporated This tutorial will discuss the information that has been stored in the lexicon. It will first deal with the types of information that have typically been placed in lexical entries, detailing what sorts of lexical information is necessary for natural language systems. The format of lexical entries and the relationships between lexical entries will be considered next (as in cases of irregularly inflected forms, such &amp;quot;go&amp;quot;, &amp;quot;went&amp;quot;, &amp;quot;gone&amp;quot;, abbreviations and acronyms, such as &amp;quot;helo&amp;quot; and &amp;quot;helicopter&amp;quot;, and derived forms, such as &amp;quot;destroy&amp;quot; and &amp;quot;destruction&amp;quot;). Alternate places for storing information will also be considered (for example, regular morphological information might be contained in individual lexical er~tries or in the grammar). The tutorial will conclude with the implications of recent work in linguistic theory for the structure of lexicons for computational purposes.</Paragraph>
</Section>
<Section position="2" start_page="0" end_page="0" type="sub_section">
<SectionTitle>
Recent Developments In Syntactic Theory and Their
Computational Import
</SectionTitle>
<Paragraph position="0"> Anthony S. Kroch, University of Pennsylvania Syntactic frameworks currently under development in linguistics take different perspectives on several issues of computational interest. Among these are: (1) the importance of stating linguistic theories in a well-defined and explicit formalism whose mathematical properties are known or investigable; (2) the degree to which the syntatic properties of sentences can be understood independently of their semantic interpretation; and (3) the extent to which empirical and mathematical results on parsing and generation can illuminate linguistic issues. We shall discuss the perspectives on these and related questions held by various current linguistic theories, including generalized phrase structure grammar (GPSG), government binding theory (GB), lexical-functional grammar (LFG), and tree adjoining grammar (TAG).</Paragraph>
<Paragraph position="1"> Current Approaches to Natural Language Semantics Graeme Hirst, University of Toronto This tutorial provides a survey of various computational approaches to semantics--the process of determining the meaning of a sentence or other utterance. Issues addressed will include definitions of meaning; the differences between linguistic theories of semantics and formalisms suitable for computational understanding of language; knowledge representations that suitable for representing linguistic meaning; the relationship between semantic processing and syntactic parsing; and factors in choosing a semantic formalism for a particular computational application. The approaches to semantics that will be discussed will include procedural semantics, conceptual dependency, Montague semantics, and compositional and knowledge-based approaches.</Paragraph>
</Section>
<Section position="3" start_page="0" end_page="0" type="sub_section">
<SectionTitle>
Machine Translation
Sergei Nirenburg, Colgate University
</SectionTitle>
<Paragraph position="0"> This tutorial will address the recent resurgence of interest in machine translation (MT) in the United States, Europe, and Japan. Topics to be discussed include the variety of objectives for MT systems; various research and developments methodologies; MT as an application area for theoretical linguistics, computational linguistics, and artificial intelligence; environments for MT research; and selected case studies of research projects.</Paragraph>
</Section>
</Section>
</Paper>

