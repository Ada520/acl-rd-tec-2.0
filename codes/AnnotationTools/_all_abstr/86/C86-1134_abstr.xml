<?xml version="1.0" standalone="yes"?>

<Paper uid="C86-1134">
<Title>LOC RED DEEP CASES LOCATIVE? DIRECTION?, LOCATIVE? DIRECTION? LOCATIVE? NIL NIL LOCATIVE? DIRECTION?, LOCATIVE? LOCATIVE? NIL DIRECTION? LOCATIVE? LOCATIVE? SOURCE?, DIRECTION? NIL</Title>
<Section position="1" start_page="0" end_page="0" type="abstr">
<SectionTitle>
Abstract
</SectionTitle>
<Paragraph position="0"> If a system that embodies a reference semanl;ic for motion verbs and prepositions is to generate a coherent text describing the recognized motions it needs it decision procedure ~,o select Ihe events. In NAOS event, selection is done by use of a specialization hierarchy of mellon verbs. The st.rategy of anticipated visualization is used tbr the selection of optional deep cases, qJhe system exhibits low-level strategies which are based on verbinherent, properties that allow the generation of a coherent descriptive I;ext.</Paragraph>
<Paragraph position="1"> t I~troductlon This contribution focuses on the verbalization component of t;he NAOS system (the acronym stands for NAtural language description of Object movements in a traffic Scene). NAOS is designed to explore the border area between computer vision and natural language processing, especially the realm of recognizing and ver-balizing motion concepts in image sequences.</Paragraph>
<Paragraph position="2"> NAOS goes all the way h'om a representation of a real~world traffic scene to a natural language text describing the scene.</Paragraph>
<Paragraph position="3"> The representation of the scene basically consists of its geometry (theretbre called geometric scene description (GSD))+ ~lk) giw~ an impression of the representation a GSD contains for each frame of the image sequence:  o instance of time o visible objects o viewpoint o illumination o 31) shape o surface characteristics (color) o class o identity 31) position and orientation in each flame (fl)r a detailed description ,,f the GSD see \[t6\]).  For event recognition we use event models (\[18\], \[191) which define a reference semantic for motion verbs. In t, he current implementation of the NAOS system about 35 motion verbs and (,he prepositions beside, 1)y, in~fronl;oof, near, and on may /&gt;e recognized by matching the event models against the representation of the scene.</Paragraph>
<Paragraph position="4"> In this paper we are neither concerned with the representation of t.he underlying scene data nor with the question of event recognition as tt ...... issues haw, bee,, put,list,ed elsewhere (see \[10\] \[171 \[20\]). Instead, we fi)cns on the generation of a coherent t;exl, describing the irnage sequel'lee.</Paragraph>
<Paragraph position="5"> In the nexl, section we brielly describe the represent, ation of the recognized events which fi)rm the initial data for the verbalizatiou eotllpo+lerlt, tl)hen I,}+e overall strategy fnr (:on+p(ming a coher(!llt description is discussed. The fblk)wing section i,ltrodnces a part, ial solution to the selection problem which is based on the strategy of anticipated visualization. Fourth, we show how some linguistic choiees like passlve~ restrictive relative elanses, and negation I thank B. Neumamt who contributed several ideas to this article. are natural consequences of the task of generating unambiguous referring expressions. In the last section we relate our research with current work on language generation.</Paragraph>
<Paragraph position="6"> \]\[nitiaJ~ \]Data Verbalization starts when event reeognil, ion has been aclfiew~d. Besides complex event, s like overtalm and turn off, other predi-cares like in-front-of, I)esi(les, move, etc. are also inst, antiated. Pleh)w is a section of the database after event recognition has taken place (the original entries are ill German).</Paragraph>
<Paragraph position="7">  1: (MOVE PERSONI 0 40) 2: (WAI,K PERSONI 0 40) 3: (RECE1)E PERSON I FBI 20 40) 4: (OWmTAKE BMW~ VWI 00:12) (~,~ 3~,)) 5: (MOVE BMW1 l0 40) 6: (IN-FRONT-OF VWl TRAFFIC-LKHITI 27 32)  &amp;quot;\]'he above entries are instantiations of event models containing symbolic identifiers for scene objects (e.g. BMWI). Tile last two elements of an instantiation denote the start and end time of the event.</Paragraph>
<Paragraph position="8"> We use the following notations to denote the event time:  ~. (....rb Te) ~. (....(r&lt;,,, Tb .... ) ('r~,,,,, r, ...... )) a. (....(rb,,.,+ Tb ...... ) &amp;quot;r.) 4. (....rb re ...... ))  Tb, Te denote start and end t, ime of an event. The first notation is used for (htratlve events (e.g. move). A duratlve event, is also valid for each subinterval of (Tb Te).</Paragraph>
<Paragraph position="9"> The secolld t+oi, ation is tlsed for ilO\]l-dllrative evelltl; (e.g. overtake). Start and end time of such an event are Imth restrk:ted by lower and upper bounds. Note, that nmt.-dnratlve events are not wdid for each subinterval of the event boundarie~L The third notation b; used for re.(mltafive events (e.g. stop). The start time ofa resnltatlve event lies within an interwd whereas the end time is a time--point.</Paragraph>
<Paragraph position="10"> Finally, the last notation is used for inchoatlve events (e.g. start moving, corresponding to the German verb loafah-. ten). )!nchoative events have a well defined start time whereas the end time lies within an interval.</Paragraph>
<Paragraph position="11"> For the task of generating a coherent description of a tra\[fic scene NAOS first instantiates all event models and predicates which may be instantiated using the scene data. This leads to the well known selection problem of natural language generation. For one object, timre may be many instantiations with different time intervals, hence the task of the verbalization component, to choose what to say. In the next section we discuss the theoretical background on which our verbalization component is based.</Paragraph>
</Section>
</Paper>

