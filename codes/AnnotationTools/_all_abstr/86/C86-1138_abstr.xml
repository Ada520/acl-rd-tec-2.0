<?xml version="1.0" standalone="yes"?>

<Paper uid="C86-1138">
<Title>Forward message Smith CMUA and these would have the nesting structure: \[ForwardAction HeadForm FORWARD MsgObj \[MsgObjDesc HeadForm MESSAGE\] MsgRecipientObj \[MaiIAdrOesc HeadForm SMITH llost \[LocationDesc HeadForm CMUA\]\]\] \[ForwardAct ion HeadForm FORWARD MsgObj \[MsgObjDesc HeadForm MESSAGE\] CCRecipientOb.j \[MailAdrDBsc HeadForm S,M I TIt Host \[Locat.i onDesc HeadEorm CMUA\]\]\] \[ForwardAction tleadForn~ FORWARD MsgObj \[MsgObjDesc HeadForm MESSAGE MsgOriginObj \[MailAdrgesc HeadForm SMITlt Itost \[LocationDesc</Title>
<Section position="1" start_page="0" end_page="0" type="abstr">
<SectionTitle>
Abstract
</SectionTitle>
<Paragraph position="0"> Parsing spoken input introduces serious problems not present in parsing typed natural language. In particular, indeterminacies and inaccuracies of acoustic recognition must be handled in an integral manner. Many techniques for parsing typed natural language do not adapt Well to these extra demands. This paper describes an extension of semantic caseframe parsing to restricted-domain spoken input. The semantic caseframe grammar representation is the same as that used for earlier work on robust parsing of typed input. Due to the uncertainty inherent in speech recognition, the caseframe grammar is applied in a quite different way, emphasizing island growing from caseframe headers. This radical change in application is possible due to the high degree of abstraction in the caseframe representation. The approach presented was tested successfully in a preliminary implementation.</Paragraph>
<Paragraph position="1"> 1. The Need for Parsing in Speech Understanding For a computer to understand and respond to a wide range of spoken natural language, it is not sufficient merely to recognize which words were spoken. As in the ea,se of typed natural language input, it is necessary to determine the meaning of the input utterance taken as a whole. The field of natural language processinrj is devoted to C/!etermining the meanings of word sequences typed into a computer. It seems, therefore, natural to apply the techniques already developed in processing typed language to (tetermining the meaning of spoken input.</Paragraph>
<Paragraph position="2"> Urffortunately, it is not possible to apply techniques for parsing typed natural language to spoken input in a straightforward manner, We list some problems below. We assume the existence of a speech recognizer that transforms a spoken input into a word lattice -- a set of hypothesized words thnt may be present, to,ether with their starting and ending times and the prob~,bility of each word being correct. In general, there will be several competing word hypotheses for each point in the input signal. This assumption is somewhat simplistic in that it does not provide any way for a parser to influence the lower levels of speech processing. However, the separation assumption helps to illustrate the following problems in adapting parsing techniques for typed input to spoken input: ~, lexical ambiguity: Mere than one word may be produced by the speech recognizer fur a given segment of speech. If the ambiguities were simply between different word choices, this could be handled by the natural language processing techniques used for word sense ~.mbiguity (e.g. &amp;quot;b:.mk&amp;quot; may be a place to put money, the side of ~ river, an action of placing trust, tilting a vehicle sideways, etc.). However, not only can multiple words be hypothesized, but the competing hypotheses can occur at overlapping, adjoining, or separate segments of the input signal, without a consistent set of word boundaries.</Paragraph>
<Paragraph position="3"> There is no parallel phenomenon for typed natural language.</Paragraph>
<Paragraph position="4"> e probability measures: Speech processing systems typically provide a relative likelihood of the correctness of each word hypothesis. These probabilities or scores are based on criteria such as the quality of the match between speech signal and phonemic dictionary expectations. Since a t~peeeh recognition system may hypothesize many words for the same segment of speech, and since these word scores may differ considerably, they are important in limiting the s.earch. However, there is no natural' way to make use of such likelihood scores in most natural language processing techniques, ,, unrecognized words: Because of hurried prenunciati0n or co-articulation effects, a speech recognizer may completely fail to recognize some words in an utterance. &amp;quot;rhe missed words are usually (though not always) short, unstressed, &amp;quot;function&amp;quot; words rather than longer &amp;quot;content&amp;quot; words, This emission is not I;andled by standard natural language processing lechniques.</Paragraph>
<Paragraph position="5"> However, new techniques for processing typed, but grammatically imperfect, input may be adaptable to this purpose since they are also designed 1o deal with missing words.</Paragraph>
<Paragraph position="6"> umj~ammatical input: In addition to the word omissions from impeHect word hypothesization, spoken inpu~ tends to contain more real gramrnatical deficiencies than typed input, Once spoken, words c~rrnot be easily retracted, bul tyl)ed utterances can be conectod if the user notices the error in time. Thus, fail-soft techniques for recovery from grammatical errors in nt~tur~J Io.nguage proces.('ing are particulc, rly pertinent when extended to the interpretatien of spoken input.</Paragraph>
<Paragraph position="7"> The.~e difficulties argue against the sirnplistic appro~tch .of atta(:hing a 8poe(.h.recognition module to a traditional natural lanpu~.t~je analyzer designed fer words ent~:red as unan~biguous AS;.II characters. No matter hew good e,';teh may be in isolation, the two will not inlegrate successfully if the I.'-~.tter cannot provide semar~tie expectations to the former, cannot handle ma.ssive lexieal arnL',ifrrity, or cannot tolerate errors of recognition and grammatical devk~don. Moreover, with adequate integration, i'eedback from a na~u~'.l language analysis component can substantially improve the perfcnn::u~ce of a COllnected speech recognizer. This performance ellh\[incemoi&amp;quot;lt is b~J(\]ly needed since no preseht connected speech recognition method comes close to human abiiil:ies. And even hLii~lt'.'.!:; of'fen fail t&lt;) rGcegnize function words exlracted from their surro~tndit\]g context. The applic~tion of linguistic knowledge and semantic expectat!ohs through natural language ~,.nalysis techniques is thus necded to cen~plement ~coustiC/ recognition methods by con:4r;~ining the set cf possible (anp! .3#!)sib!e) hdct pletadon,'; of the words in an input utterance.</Paragraph>
</Section>
</Paper>

