<?xml version="1.0" standalone="yes"?>

<Paper uid="P87-1031">
<Title>Expressing Concern</Title>
<Section position="1" start_page="0" end_page="221" type="abstr">
<SectionTitle>
Abstract
</SectionTitle>
<Paragraph position="0"> A consultant system's main task is to provided helpful advice to the user. Consultant systems should not only find solutions to user problems, but should also inform the user of potential problems with these solutions. Expressing such potential caveats is a difficult process due to the many potential plan failures for each particular plan in a particular planning situation. A commonsense planner, called KIP, Knowledge Intensive Planner, is described. KIP is the planner for the UNIX Consultant system. KIP detect potential plan failures using a new knowledge structure termed a concern. Concerns allow KIP to detects plan failures due to unsatisfied conditions or goal conflict. KIP's concern algorithm also is able to provide information to the expression mechanism regarding potential plan failures. Concern information is passed to the expression mechanism when KIP's selected plan might not work. In this case, KIP passes information regarding both the suggested plan and the potential caveats in that plan to the expression mechanism. This is an efficient approach since KIP must make such decisions in the context of its planning process. A concern's declarative structure makes it easier to express than procedural descriptions of plan failures used by earlier systems. null  (a2) Let me know if the door is locked.</Paragraph>
<Paragraph position="1"> (a3) Be careful walking down the stairs.</Paragraph>
<Paragraph position="2"> (a4) Make sure to turn off the basement light.</Paragraph>
<Paragraph position="3">  In (al), the mother has provided the child with information about the location of his shoe. The mother has also implied the use of a plan: Walk down to the basement and get your shoes. However, there are a number of problems inherent in this plan. The mother might also inform her child of these problems. The first problem, (a2), is that one of the conditions necessary to execute the plan might be unsatisfied. The door to the basement might be locked. If it is locked additional steps in the plan will be necessary. The second problem, (a3), is that executing the walk-down-the-stairs plan might result in a fall. The mother knows that this outcome is likely, due to her experience of the child's previous attempts at the walk-down-the-stairs plan. The mother wishes to prevent the child from falling, since this is a potentially dangerous and frightening experience for the child. The third problem, (a4), is that the child might forget to turn off the light in the basement. This would threaten the mothers's goal of preventing the basement light from burning out.</Paragraph>
<Paragraph position="4"> However, the same parent might not add: I. Introduction The most important task of a consultant is to provide advice to a user. Human consultants are asked to provide answers to user queries in domains within which they have more expertise than the user. In some cases, the answers provided to the user are basic information about a particular domain. However, in many cases, the task of the consultant is provide answers to user problems. Furthermore, they are not only asked to find solutions, they are also asked to use their expertise to anticipate potential problems with these solutions. Let us consider a very simple example of a consultant relationship. For example, suppose a child asks the following question: (a) Where is my shoe? His mother might respond: (al) It's in the basement.</Paragraph>
<Paragraph position="5"> However, his mother might also add:  (a5) Let me know if the door needs to be oiled (a6) Be careful walking in the basement (a7) Make sure to close the basement door  This second set of responses also provide advice that reflects problems due to unsatisfied conditions of the plan or potential goal conflicts. However, the mother might not decide to express these statements to the child since they are either unlikely or unimportant causes of potential plan failure. Therefore, the mother has made three decisions. First, she has decided which plan to suggest to the child based on his world knowledge. Secondly, she has decided which parts of that plan should be expressed to the child. Thirdly, she has decided which potential caveats in that plan should be expressed to the child based on her experience.</Paragraph>
<Paragraph position="6"> Previous research in intelligent user interfaces (Allen84, Appelt85, McDonald84) has focused on the second decision. Systems attempt not to violate Grice's second Maxim of Quantity: Make your contribution as informative as is required (Grice 1975). These systems formulated a response  that would provide information or a plan to the user. Allen sought to discover obstacles in the user's plan. He tried to help the user's plan by providing the user with the information he needed to execute that plan. However, he did not provide a mechanism for expressing plan failures. In this paper, we focus on the problem of making decisions regarding those potential problems which should be expressed to the user. However, rather than using a separate mechanism for this purpose, we propose that this decision be made using information provided by the problem solving component of the system, the planner.</Paragraph>
<Paragraph position="7"> We describe a commonsense planner called KIP, Knowledge Intensive Planner. KIP is being developed for UC, the UNIX Consultant system (Luria85, Wilensky 84a, 86). UC provides solutions to user problems in the UNIX operating system domain. KIP provides the information necessary in order to make decisions regarding which potential plan failures should be expressed to the user. KIP must make decisions regarding potential plan failures in order to devise a good plan for the user. Rather than use a separate process to make decisions about those potential plan failures which should be expressed to the user, KIP provides this information to the expression mechanism directly. In the next section, we give some examples of KIP's interaction with expression mechanism. KIP provides information about potential plan failures which will be expressed to the user. We also describe KIP's role in the UNIX Consultant system. In the following section, we describe a declarative representation that allows KIP to detect and provide expression information  about potential plan failures.</Paragraph>
<Paragraph position="8"> 2. KIP Examples (b) User: UC: How do I print Jim's file on the lineprinter? Print Jim's file foo by typing ipr foo. This plan will not work if you don't have read permission on Jim's file or if the printer is out of paper.</Paragraph>
<Paragraph position="9"> (c) User: UC:  How do I move a file named paul to the file named mary? To move the file paul to the file named mary, type mv paul mary. However, if the file mary exists, it will be deleted.</Paragraph>
<Paragraph position="10">  (d) User: UC:  How do I change my password? To change your passwd use the passwd command. However, remember that if you change your password on one machine, it will not be changed on other machines.</Paragraph>
<Paragraph position="11"> In each of these examples, KIP has selected a known plan for accomplishing the goals of the user. However, in each of these examples, KIP determines that the plan could fail and therefore has decided to express this potential failure to the user.</Paragraph>
<Paragraph position="12"> KIP has a large knowledge-base of information about the UNIX operating system. Decisions regarding UC's own actions are made by UCEgo. The parser and goal analyzer (Mayfield 86) of UC pass KIP a set of goals, and KIP wies to find appropriate plans for those goals. KIP determines a plan for the problem, and notes which potential plan failures should be expressed to the user. KIP passes this decision-making information to the UCExpression mechanism(Chin86, Wilensky86). The expression mechanism decides how to express the plan to the user, given a model of the user's knowledge about UNIX. The plan is then passed to the natural language generator, which generates a natural language response to the user. UC is a conversational system, and if necessary KIP can query the user for more information. Nevertheless, KIP tries to provide the best plan it can with the information provided by user.</Paragraph>
</Section>
</Paper>

