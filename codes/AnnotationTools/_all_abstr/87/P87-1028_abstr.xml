<?xml version="1.0" standalone="yes"?>

<Paper uid="P87-1028">
<Title>Lexica\] Selection in the Process of Language Generation</Title>
<Section position="2" start_page="0" end_page="201" type="abstr">
<SectionTitle>
Abstract
</SectionTitle>
<Paragraph position="0"> In this paper we argue that lexical selection plays a more important role in the generation process than has commonly been assumed. To stress the importance of lexical-semantic input to generation, we explore the distinction and treatment of generating open and closed cla~s lexical items, and suggest an additional classification of the latter into discourse-oriented and proposition-oriented items.</Paragraph>
<Paragraph position="1"> Finally, we discuss how lexical selection is influenced by thematic (\[oc~) information in the input.</Paragraph>
<Paragraph position="2"> I. Introduction There is a consensus among computational linguists that a comprehensive analyzer for natural language must have the capability for robust lexical disambiguation, i.e., its central task is to select appropriate meanings of lexical items in the input and come up with a non contradictory, unambiguous representation of both the propositional and the non-propositional meaning of the input text. The task of a natural language generator is, in some sense, the opposite task of rendering an unambiguous meaning in a natural language. The main task here is to to perform principled selection of a) lexical items and b) the syntactic structure for input constituents, based on lexical semantic, pragmatic and discourse clues available in the input. In this paper we will discuss the problem of lexlcal selection.</Paragraph>
<Paragraph position="3"> The problem of selecting lexical items in the process of natural language generation has not received as much attention as the problems associated with expressing explicit grammatical knowledge and control. In most of the generation systems, lexical selection could not be a primary concern due to the overwhelming complexity of the generation problem itself. Thus, MUMBLE concentrates on gr:~mmar-intensive control decisions (McDonald and Pustejovsky, 1985a) and some stylistic considerations (McDonald and Pustejovsk'y, 1985b); TEXT (McKeown, 1985) stresses the strategical level of control decisions about the overall textual shape of the generation output.</Paragraph>
<Paragraph position="4"> ~KAMP (Appelt, 1985) emphasizes the role that dynamic planning plays in controlling the process of generation, and specifically, of referring expressions; NIGEL (Mann and Matthiessen, 1983) derives its control structures from the choice systems of systemic grammar, concentrating on grammatical knowledge without fully realizing the 'delicate' choices between elements of what systemicists call leto's (e.g., HaLiiday, 1961). Thus, the survey in Cummlng (1986) deals predominantly with the grammatical aspects of the lexicon.</Paragraph>
<Paragraph position="5"> We discuss here the problem of lexical selection and explore the types of control knowledge that are necessary for it. In particular, we propose different control strategies and epistemological foundations for the selection of members of a) open-class and b) closed-class lexical items. One of the most important aspects of control knowledge our generator employs for lexical selection is the non-propositional information (including knowledge about focus and discourse cohesion markers). Our generation system incorporates the discourse and textual knowledge provided by TEXT as well as the power of MUMBLE's grammatical constraints and adds principled lexical selection (based on a large semantic knowledge base) and a control structure capitalizing on the inherent flexibility of distributed architectures. 2 The specific innovations discussed in this paper are: I Derr and McKeown, 1984 and McKeown, 1985, however, discuss thematic information, i,e. focus, as a basis for the selection of anaphoric pronouns. This is a fruitful direction, and we attempt to extend it for treatment of additional discourse-based phenomena.</Paragraph>
<Paragraph position="6"> 2 Rubinoff (1986) is one attempt st integrating the textual component of TEXT with the grammar of MUMBLE. This interesting idea leads to a significant improvement in the performance of sentence production. Our approach differs from this effort in two important repsects. First, in Rubinoff's system the output of TEXT serves as the input to MUMBLE, resulting in a cascaded process. We propose a distributed control where the separate knowledge sources contribute to the control when they can, opportunistically. Secondly, we view the generation process as the product of many more components than the number proposed in current generators. For a detailed discussion of these see Nirenburg and Pu~tejovslry, in preparation.</Paragraph>
<Paragraph position="7">  I. We attach importance to the question of what the input to a generator should be, both as regards its content and its form; thus, we maintain that discourse and pragmatic information is absolutely essentiM in order for the generator to be able to handle a large class of lexicM phenomena; we distinguish two sources of knowledge for lexicM selection, one discourse and pragznatics-based, the other lexicM semantic.</Paragraph>
<Paragraph position="8"> 2. We argue that lexicM selection k not just a side ei~ect of grammatical decisions but rather ~ts to flexibly constrain concurrent and later generation decisions of either lexicM or ~aticM type.</Paragraph>
<Paragraph position="9"> For comparison, MUMBLE lexical selections are performed after some grammatical constraints have been used to determine the surface syntactic structure; this type of control of the generation process does not seem optimal or su~icient for all generation tasks, although it may be appropriate for on-line generation models; ; we argue that the decision process is greatly enhanced by making lexicM choices early on in the process. Note that the above does not presuppose that the control structure for generation ls to be like cascaded transducers; in fact, the actual system that we are building based on these principles, features a distributed architecture that supports non-rigid decision making (it follows that the lexical and grammatical decisions are not explicitly ordered with respect to each other). This architecture is discussed in detail in Nirenburg ~nd Pustejovsky, in preparation.</Paragraph>
<Paragraph position="10"> 3. We introduce an important distinction between open-class and closed-class lexical items in the way they are represented as well as the way they are processed by our generator; our computational, processing-oriented paradigm has led us to develop a finer classification of the closed-class items than that tr~litionMly acknowledged in the psycholinguistic literature; thus, we distinguish between discourse oriented closed-class (DOCC) items and proposition oriented ones (POCC); 4. We upgrade the importance of knowledge about focus in the sentence to be generated so that it becomes one of the prime heuristics for controlling the entire generation process, including both lexical selection and grammatical phrasing.</Paragraph>
<Paragraph position="11"> 5. We suggest a comprehensive design for the concept lexicon component used by the generator, which is perceived as a combination of a gener'M-purpose semantic knowledge base describing a subject domain (a subworld) and a generation-specific lexicon (indexed by concepts in this knowledge base) that consists of a large set of discrimination nets with semantic and pragmatic tests on their nodes.</Paragraph>
<Paragraph position="12"> These discrimination nets are distinct from the choosers in NIGEL's choice systems, where grammatical knowledge is not systematically separated from the lexical semantic knowledge (for a discussion of problems inherent in this approach see McDonald, Vaughau and Pustejovsky, 1986); the pragmatic nature of some of the tests, as well ms the fine level of detail of knowledge representation is what distinguishes our approach from previous conceptual generators, notably PHRED (Jscobs, 1985)).</Paragraph>
</Section>
</Paper>

