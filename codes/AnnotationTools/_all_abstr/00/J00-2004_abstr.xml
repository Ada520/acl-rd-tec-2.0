<?xml version="1.0" standalone="yes"?>

<Paper uid="J00-2004">
<Title>Models of Translational Equivalence among Words</Title>
<Section position="2" start_page="0" end_page="0" type="abstr">
<SectionTitle>
1. Introduction
</SectionTitle>
<Paragraph position="0"> The idea of a computer system for translating from one language to another is almost as old as the idea of computer systems. Warren Weaver wrote about mechanical translation as early as 1949. More recently, Brown et al. (1988) suggested that it may be possible to construct machine translation systems automatically. Instead of codifying the human translation process from introspection, Brown and his colleagues proposed machine learning techniques to induce models of the process from examples of its input and output. The proposal generated much excitement, because it held the promise of automating a task that forty years of research have proven very labor-intensive and error-prone. Yet very few other researchers have taken up the cause, partly because Brown et al.'s (1988) approach was quite a departure from the paradigm in vogue at the time.</Paragraph>
<Paragraph position="1"> Formally, Brown et al. (1988) built statistical models of translational equivalence (or translation models 1, for short). In the context of computational linguistics, translational equivalence is a relation that holds between two expressions with the same meaning, where the two expressions are in different languages. Empirical estimation of statistical translation models is typically based on parallel texts or bitexts--pairs of texts that are translations of each other. As with all statistical models, the best translation models are those whose parameters correspond best with the sources of variance in the data. Probabilistic translation models whose parameters reflect universal properties of translational equivalence and/or existing knowledge about particular * D1-66F, 610 Opperman Drive, Eagan, MN 55123. E-marl: dan.melamed@westgroup.com 1 The term translation model, which is standard in the literature, refers to a mathematical relationship between two data sets. In this context, the term implies nothing about the process of translation between natural languages, automated or otherwise.</Paragraph>
<Paragraph position="2"> @ 2000 Association for Computational Linguistics Computational Linguistics Volume 26, Number 2 languages and language pairs benefit from the best of both the empiricist and rationalist traditions.</Paragraph>
<Paragraph position="3"> This article presents three such models, along with methods for efficiently estimating their parameters. Each new method is designed to account for an additional universal property of translational equivalence in bitexts: .</Paragraph>
<Paragraph position="4"> .</Paragraph>
<Paragraph position="5"> .</Paragraph>
<Paragraph position="6"> Most word tokens translate to only one word token. I approximate this tendency with a one-to-one assumption.</Paragraph>
<Paragraph position="7"> Most text segments are not translated word-for-word. I build an explicit noise model.</Paragraph>
<Paragraph position="8"> Different linguistic objects have statistically different behavior in translation. I show a way to condition translation models on different word classes to help account for the variety.</Paragraph>
<Paragraph position="9"> Quantitative evaluation with respect to independent human judgments has shown that each of these three estimation biases significantly improves translation model accuracy over a baseline knowledge-free model. However, these biases will not produce the best possible translation models by themselves. Anyone attempting to build an optimal translation model should infuse it with all available knowledge sources, including syntactic, dictionary, and cognate information. My goal here is only to demonstrate the value of some previously unused kinds of information that are always available for translation modeling, and to show how these information sources can be integrated with others.</Paragraph>
<Paragraph position="10"> A review of some previously published translation models follows an introduction to translation model taxonomy. The core of the article is a presentation of the model estimation biases described above. The last section reports the results of experiments designed to evaluate these innovations.</Paragraph>
<Paragraph position="11"> Throughout this article, I shall use CAPSPS/~GT4A/~C letters to denote entire text corpora and other sets of sets, CAPITAL letters to denote collections, including sequences and bags, and italics for scalar variables. I shall also distinguish between types and tokens by using bold font for the former and plain font for the latter.</Paragraph>
</Section>
</Paper>

