<?xml version="1.0" standalone="yes"?>

<Paper uid="W97-1408">
<Title>Generating Referential Descriptions in Multimedia Environments</Title>
<Section position="1" start_page="0" end_page="0" type="abstr">
<SectionTitle>
Abstract
</SectionTitle>
<Paragraph position="0"> All known algorithms dedicated to the generation of referential descriptions use natural language alone to accomplish this communicative goal. Motivated by some limitations underlying these algorithms and the resulting restrictions in their scope, we attempt to extend the basic schema of these procedures to multi-media environments, that is, to descriptions consisting of images and text. We discuss several issues in this enterprise, including the transfer of basic ingredients to images and the hereby reinterpretation of language-specific concepts, matters of choice in the generation process, and the extended application potential in some typical scenarios. Moreover, we sketch our intended area of application, the identification of a particular object in the large visualization of mathematical proofs, which has some characteristic properties of each of these scenarios. Our achievement lies in extending the scope of techniques for generating referential descriptions through the incorporation of multimedia components and in enhancing the application areas for these techniques.</Paragraph>
</Section>
</Paper>

