<?xml version="1.0" standalone="yes"?>

<Paper uid="H94-1049">
<Title>A Report of Recent Progress in Transformation-Based Error-Driven Learning*</Title>
<Section position="1" start_page="0" end_page="0" type="abstr">
<SectionTitle>
ABSTRACT
</SectionTitle>
<Paragraph position="0"> Most recent research in trainable part of speech taggers has explored stochastic tagging. While these taggers obtain high accuracy, linguistic information is captured indirectly, typically in tens of thousands of lexical and contextual probabilities. In \[Brill 92\], a trainable rule-based tagger was described that obtained performance comparable to that of stochastic taggers, but captured relevant linguistic information in a sma\]_l number of simple non-stochastic rules. In this paper, we describe a number of extensions to this rule-based tagger. First, we describe a method for expressing lexical relations in tagging that stochastic taggers are currently unable to express. Next, we show a rule-based approach to tagging unknown words. Finally, we show how the tagger can be extended into a k-best tagger, where multiple tags can be assigned to words in some cases of uncertainty.</Paragraph>
<Section position="1" start_page="0" end_page="0" type="sub_section">
<SectionTitle>
Spoken Language Systems Group
</SectionTitle>
<Paragraph position="0"> that achieves performance comparable to that of stochastic taggers. Training this tagger is fully automated, but unlike trainable stochastic taggers, linguistic information is encoded directly in a set of simple non-stochastic rules.</Paragraph>
<Paragraph position="1"> In this paper, we describe some extensions to this rule-based tagger. These include a rule-based approach to: lexicalizing the tagger, tagging unknown words, and assigning the k-best tags to a word. All of these extensions, as well as the original tagger, are based upon a learning paradigm called transformation-based error-driven learning. This learning paradigm has shown promise in a number of other areas of natural language processing, and we hope that the extensions to transformation-based learning described in this paper can carry over to other domains of application as well. 2</Paragraph>
</Section>
</Section>
</Paper>

