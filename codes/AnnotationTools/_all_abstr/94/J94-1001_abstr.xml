<?xml version="1.0" standalone="yes"?>

<Paper uid="J94-1001">
<Title>Computing with Features as Formulae</Title>
<Section position="2" start_page="0" end_page="2" type="abstr">
<SectionTitle>
1. Introduction
</SectionTitle>
<Paragraph position="0"> Despite their simplicity, a surprisingly wide range of linguistic phenomena can be described in terms of simple equality constraints on values in attribute-value structures, which are a particularly simple kind of feature structure (see Shieber 1986; Johnson 1988; Uszkoreit 1986; and Bresnan 1982 for examples of some of these analyses). But some phenomena do not seem to be able to be described in such a pure 'unification' framework. For example, the analysis of conjunctions in LFG (Kaplan and Maxwell 1988b) and the formalizations of Discourse Representation Theory (Kamp 1981) presented in Johnson and Klein (1986) and Johnson and Kay (1990) require additional mechanisms for representing and manipulating aggregates or sets of values in ways that are beyond the capability of such &amp;quot;pure&amp;quot; attribute-value systems. Further, sortal constraints (which also cannot be expressed as simple equality constraints) can be used to formulate simpler and more comprehensible grammars (Carpenter 1992; Carpenter and Pollard 1991; Pollard and Sag 1987, 1992).</Paragraph>
<Paragraph position="1"> Versions of both of these kinds of constraint, as well as the familiar attribute-value constraints, can be expressed as Scho'nfinkel-Bernays'formulae (as demonstrated in Johnson 1991a, 1991b), so that the problem of determining the satisfiability of a system of such constraints is reduced to the satisfiability problem for the corresponding formula.</Paragraph>
<Paragraph position="2"> This class of formulae (defined in Section 3.1) seems to be expressive enough for most linguistic purposes when used with an external phrase-structure backbone. That is, these formulae are used as annotations on phrase structure rules in the manner described in, e.g., Kaplan and Bresnan (1982), Shieber (1986), and Johnson (1988). This paper extends the author's previous paper on the topic (Johnson 1991a) by sketching several other linguistic applications of Sch6nfinkel-Bernays' formulae (including a version of D-theory \[Marcus, Hindle, and Fleck 1983; Vijay-Shanker 1992\]), and presenting a least-fixed-point theorem that serves as the theoretical basis for a &amp;quot;forwardchaining&amp;quot; algorithm for determining satisfiability of Sch6nfinkel-Bernays' formulae. Interestingly, this algorithm can be viewed both as a straightforward generalization * Cognitive and Linguistic Sciences, Box 1978, Brown University, Providence, RI. E-mail: Mark_Johnson@brown.edu Q 1994 Association for Computational Linguistics Computational Linguistics Volume 20, Number 1 of the standard attribute-value unification algorithm and also as a nondeterministic variant of the semi-naive evaluation method for Datalog clauses.</Paragraph>
<Paragraph position="3"> Several extended &amp;quot;unification-based&amp;quot; constraint formalisms have been developed.</Paragraph>
<Paragraph position="4"> In this paper, the term &amp;quot;feature structure&amp;quot; denotes any kind of structured entity used as a component of a category label. An attribute-value structure is a particularly simple kind of feature structure of the kind used in &amp;quot;pure&amp;quot; unification-based frameworks (Shieber 1986). Some extensions to the basic attribute-value framework are rather weak, e.g., allowing disjunctive and negative constraints and preserving decidability. 1 Such systems require an &amp;quot;off-line&amp;quot; phrase structure backbone to which these constraints are attached. It seems that most of the constraints that can be expressed in these formalisms can be expressed as Sch6nfinkel-Bernays' formulae, the constraint formalism described below.</Paragraph>
<Paragraph position="5"> A second class of extended constraint formalisms has been devised to be capable of expressing the entire grammar as systems of constraints and as far as I know, for all of these systems the problem of determining the satisfiabihty of an arbitrary system of constraints that they can express is undecidable. 2 This is because the recognition problem for an arbitrary &amp;quot;unification-based&amp;quot; grammar is undecidable unless the size of the phrase structure tree is constrained somehow, e.g., by the offiine parsability constraint (Johnson 1988; Kaplan and Bresnan 1982; Pereira 1982; Shieber 1992), but there seems to be no natural way to impose such constraints in these systems because the encoding of the phrase structure tree in the feature structure is not distinguished from other features. 3 Thus in order to maintain decidability the system described here is not designed to be capable of expressing phrase structure constraints directly, and must be used with an external phrase-structure component, as in LFG (Bresnan 1982). (However, Bob Carpenter \[p.c.\] points out that one can impose a bound on the size of the feature structure that can serve as an analysis \[say, some polynomial of the length of the input\], and so ensure decidability.) Interestingly, a first-order logic-based approach similar to the one presented in this paper can also be developed for extended constraint formalisms capable of expressing the entire grammar, but this is not discussed further here; see Johnson (in press b) for details.</Paragraph>
<Paragraph position="6"> In the approach developed here Sch6nfinkel-Bernays' formulae are used to express a variety of feature structure constraints. Previous work has shown that these formulae are expressive enough to define arbitrary disjunctions and negations of constraints (Johnson 1990a, 1990b), a kind of 'set-valued' entity (Johnson 1991a), and they can be used to impose useful sort constraints (Johnson 1991b). The expression of D-theory constraints on nodes in trees is discussed in this paper.</Paragraph>
<Paragraph position="7"> This paper extends the ideas in these earlier papers with theoretical results that suggest a forward-chaining algorithm for determining the satisfiability of an arbitrary Sch6nfinkel-Bernays' formula. This generalizes the standard feature-graph unification algorithm and is closely related to the semi-naive bottom-up algorithm used in database theory.</Paragraph>
<Paragraph position="8">  undecidable (Chomsky \[1986, 1988\] points out that there is no contrary evidence), I know of no evidence that this is actually the case. It seems reasonable then to also investigate formalisms that can only express decidable systems of constraints (and for which there exist satisfiability-testing algorithms) if linguistically adequate systems can be found.</Paragraph>
<Paragraph position="9">  Mark Johnson Computing with Features as Formulae Specifically, it is shown that the satisfying Herbrand models of an arbitrary Sch6nfinkel-Bernays' formula are the fix points of certain functions, and that the least fixed points of these functions are all of the models of the formula that are &amp;quot;minimal&amp;quot; in a certain sense. This leads to a forward-chaining algorithm for computing all of the atomic consequences of a Sch6nfinkel-Bernays' formula; the fixed-point theorem shows that this suffices to determine the satisfiability of an arbitrary Sch6nfinkel-Bernays' formula.</Paragraph>
<Paragraph position="10">  2. Constraints, Partial Information, and Feature Structures  This approach exploits the fact that constraints on well-formed linguistic structures (e.g., well-formedness constraints imposed by the grammar) do not need to be isomorphic to the structures that satisfy them. Although the distinction between constraints and structures that satisfy them might seem too obvious to warrant comment, it is not made in most work on feature structures.</Paragraph>
<Paragraph position="11"> A common view holds that feature structures are inherently &amp;quot;partially specified&amp;quot; entities, which &amp;quot;unify&amp;quot; or merge with other feature structures to yield more instantiated feature structures in an &amp;quot;information-preserving&amp;quot; way (Shieber 1986). If two feature structures contain &amp;quot;contradictory information,&amp;quot; then it is impossible to merge them to produce a consistent object; unification is then said to fail. The feature structure for an utterance is the result (if one exists) of unifying all of the feature structures for the lexical entries and syntactic rules in appropriate ways. Thus in this view feature structures play two roles; not only do they serve as linguistic structures, but they are also used to encode constraints that the linguistic structures must satisfy (see Section 2.10 of Johnson (1988) for an extended discussion).</Paragraph>
<Paragraph position="12"> That is, under this view feature structures serve not only as linguistic structures that may or may not satisfy a constraint, but are also interpreted as 'representing' or 'describing' all of the feature structures that they subsume. Given this dual role for feature structures, it is important in this approach that if a feature structure S satisfies a constraint o~, then every feature structure subsumed by S should also satisfy o~ (Pereira 1987). If this &amp;quot;upward closure&amp;quot; property holds, then the set of feature structures satisfying any constraint can be represented by the set of its &amp;quot;minimal models.&amp;quot; Unfortunately, many useful constraints do not have this property. For example, under a classical interpretation, the set of feature structures satisfying negated feature structure constraints are not upward-closed (Moshier and Rounds 1987).</Paragraph>
<Paragraph position="13"> The work described in this paper pursues a different approach. Following Kaplan and Bresnan (1982), feature structures are only (components of) linguistic structures, and not partial descriptions of (other) linguistic structures. As such, a feature structure either does or does not satisfy any particular set of constraints. An utterance is well-formed just in case there is some linguistic structure that satisfies all of the constraints imposed by the grammar and has the phonological form of that utterance as its phonological form (which itself is just another constraint that the structure must satisfy). Since the relationship between a feature structure and a constraint that it satisfies is essentially the same as the relationship between an interpretation and a formula that is true under that interpretation, it seems natural to conceive of a constraint as a kind of formula (in a format that allows efficient computational manipulation) that has feature structures as its intended interpretations.</Paragraph>
<Paragraph position="14"> This approach is more general in that it does not rely on the upward-closure property, and it allows constraints on feature structures to have a structure quite different from the feature structures that they constrain. The subsumption relation on Computational Linguistics Volume 20, Number 1 feature structures plays no special role in this approach; specifically, it is not required that the set of structures that satisfy a constraint be upward-closed.</Paragraph>
<Paragraph position="15"> In general, a linguistic structure S must satisfy several constraints, say oaT... ~ o~,~, in order to be well formed, so in order to solve the recognition and parsing problems, all we need do is determine if there are any S that satisfy oq~... ~ O~n, and if so, describe them somehow.</Paragraph>
<Paragraph position="16"> It is convenient to devise a language for expressing constraints, so that the o~i are well-formed formulae of this language, and its satisfaction relation is exactly the satisfaction relation mentioned above. Viewed from this perspective, the problem of determining if there is a structure S that satisfies the constraints o~1~ ...~ O~n is the same as the problem of determining if the formula c~ is satisfiable, where o~ is Oq A &amp;quot;'&amp;quot; /X O~ n and conjunction is given the standard interpretation. Algorithms for deciding the satisfiability of arbitrary formulae in this language (if they exist) can therefore be used to determine the satisfiability of the linguistic constraints. Moreover, if o~ ~ c~ ~ then o/is a true description of every model of c~, i.e., the logical consequences of o~ are descriptions of every well-formed linguistic structure that satisfies the constraints. Thus the logic of the constraint language provides in principle all the necessary tools for determining if a set of constraints are satisfiable, and if they are, providing descriptions of the satisfying structures.</Paragraph>
<Paragraph position="17"> From this perspective, an &amp;quot;information state&amp;quot; is a kind of formula, and &amp;quot;unifying&amp;quot; two such information states is accomplished by conjoining them and simplifying the resulting formula, not by some manipulation of their models. Partial information states are those that are satisfied by more than one interpretation. The consequence relation corresponds to the subsumption relation of traditional unification grammar (a formula o~ &amp;quot;contains more information&amp;quot; than formula o/iff o~ ~ a'), and unsatisfiability corresponds to unification failure.</Paragraph>
</Section>
</Paper>

