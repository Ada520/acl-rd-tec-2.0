<?xml version="1.0" standalone="yes"?>

<Paper uid="J99-3004">
<Title>Interpreting and Generating Indirect Answers</Title>
<Section position="2" start_page="0" end_page="391" type="abstr">
<SectionTitle>
1. Introduction
</SectionTitle>
<Paragraph position="0"> In the following example, 1 Q asks a question in (1)i and R provides the requested information in (1)iii, although not explicitly giving (1)ii. (In this paper, we use square brackets as in (1)ii to indicate information which, in our judgment, the speaker intended to convey but did not explicitly state. For consistency, we refer to the questioner and responder as Q and R, respectively. For readability, we have standardized punctuation and capitalization and have omitted prosodic information from sources since it is not used in our model.) (1) i. Q: Actually you'll probably get a car won't you as soon as you get there? ii. R: \[No.\] iii. I can't drive.</Paragraph>
<Paragraph position="1"> Interpreting such responses, which we refer to as indirect answers, requires the hearer to derive a conversational implicature (Grice 1975). For example, the inference that R Department of Mathematical Sciences, Greensboro, NC 27412-5001 t Department of Computer and Information Sciences, Newark, DE 19716 1 Based on an example on page 220 in Stenstr6m (1984). The reader may assume that any unattributed examples in the paper are constructed.</Paragraph>
<Paragraph position="2"> (~) 1999 Association for Computational Linguistics Computational Linguistics Volume 25, Number 3 will not get a car on arrival, although licensed by R's use of (1)iii in some discourse contexts, is not a semantic consequence of the proposition that R cannot drive. According to one study of spoken English (Stenstr6m 1984) (described in Section 2), 13% of responses to certain yes-no questions were indirect answers. Thus, a robust dialogue system should be able to interpret indirect answers. Furthermore, there are good reasons for generating an indirect answer instead of just a yes or no answer. First, an indirect answer may be considered more polite than a direct answer (Brown and Levinson 1978). For example, in (1)i, Q has indicated (by the manner in which Q expressed the question) that Q believes it likely that R will get a car. By avoiding explicit disagreement with this belief, the response in (1)iii would be considered more polite than a direct answer of (1)ii. Second, an indirect answer may be more efficient than a direct answer. For example, even if (1)ii is given, including (1)iii in R's response contributes to efficiency by forestalling and answering a possible follow-up of well, why not? from Q, which can be anticipated since the form of Q's question suggests that Q may be surprised by a negative answer. Third, an indirect answer may be used to avoid misleading Q (Hirschberg 1985), as illustrated in (2). 2 (2) i. Q: Have you gotten the letters yet? ii. R: I've gotten the letter from X.</Paragraph>
<Paragraph position="3"> This example illustrates a case in which, provided that R had gotten some but not all of the letters in question, just yes would be untruthful and just no would be misleading (since Q might conclude from the latter that R had gotten none of them).</Paragraph>
<Paragraph position="4"> We have developed a computational model, implemented in Common LISP, for interpreting and generating indirect answers to yes-no questions in English (Green 1994). By a yes-no question we mean one or more utterances used as a request by Q that R convey R's evaluation of the truth of a proposition p. Consisting of one or more utterances, an indirect answer is used to convey, yet does not semantically entail, R's evaluation of the truth of p, i.e., that p is true, that p is false, that p might be true, that p might be false, or that p is partially true. In contrast, a direct answer entails R's evaluation of the truth of p. The model presupposes that Q and R mutually believe that Q's question has been understood by R as intended by Q, that Q's question is appropriate, and that R can provide one of the above answers. Furthermore, it is assumed that Q and R are engaged in a cooperative and polite task-oriented dialogue. 3 The model is based upon examples of uses of direct and indirect answers found in transcripts of two-person telephone conversations between travel agents and their clients (SRI 1992), examples given in previous studies (Brown and Levinson 1978; Hirschberg 1985; Kiefer 1980; Levinson 1983; Stenstr6m 1984) and constructed examples reflecting our judgments.</Paragraph>
<Paragraph position="5"> To give an overview of the model, generation and interpretation are treated, respectively, as construction of and recognition of the responder's discourse plan specification for a full answer. In general, a discourse plan specification (for the sake of brevity, hereafter referred to as discourse plan) explicitly relates a speaker's beliefs and discourse goals to his program of communicative actions (Pollack 1990). Discourse plan construction and recognition make use of the beliefs that are presumed  and interpretation. For example in generation, it would seem to be a desirable trait for a software agent that interacts with humans. In interpretation, it would contribute to the robustness of the interpreter.  Green and Carberry Indirect Answers to be shared by the participants, as well as shared knowledge of discourse strategies, represented in the model by a set of discourse plan operators encoding generic programs of communicative actions for conveying full answers. A full answer consists of a direct answer, which we refer to as the nucleus, and &amp;quot;extra&amp;quot; appropriate information, which we refer to as the satellite(s). 4 In the operators, coherence relations are used to characterize types of satellites that may accompany each type of answer. Stimulus conditions are used to characterize the speaker's motivation for including a satellite. An indirect answer is the result of the speaker (R) expressing only part of the planned response, i.e., omitting the direct answer (and possibly more), but intending for his discourse plan to be recognized by the hearer (Q). Furthermore, we argue that because of the role of interpretation in generation, Q's belief that R intended for Q to recognize the answer is warranted by Q's recognition of the plan.</Paragraph>
<Paragraph position="6"> The inputs to the interpretation component of the model (a model of Q's interpretation of an indirect answer) are the semantic representation of the questioned proposition, the semantic representation of the utterances given by R during R's turn, shared pragmatic knowledge, and Q's beliefs, including those presumed by Q to be shared with R. (Beliefs presumed by an agent to be shared by another agent are hereafter referred to as shared beliefs, and those that are not presumed to be shared as nonshared beliefs). 5 The output is a set of alternative discourse plans that might be ascribed to R by Q, ranked by plausibility. R's inferred discourse plan provides the intended answer and possibly other information about R's beliefs and intentions. The inputs to the generation component (a model of R's construction of a response) are the semantic representation of the questioned proposition, shared pragmatic knowledge, and R's beliefs (both shared and nonshared). The output of generation is R's discourse plan for a full answer, including a specification of which parts of the plan do not need to be explicitly given by R, i.e., which parts should be inferable by Q from the rest of the answer. 6 This paper describes the knowledge and processes provided in our model for interpreting and generating indirect answers. (The model is not intended as a cognitive model, i.e., we are not claiming that it reflects the participants' cognitive states during the time course of comprehension and generation. Rather, its purpose is to compute the end products of comprehension and generation, and to contribute to a computational theory of conversational implicature.) As background, Section 2 describes some relevant generalizations about questions and answers in English. Section 3 describes the reversible knowledge in our model, i.e., knowledge used both in interpretation and generation of indirect answers. Sections 4 and 5 describe the interpretation and generation components, respectively. Section 5 includes a description of additional pragmatic knowledge required for generation. Section 6 provides an evaluation of the work. Finally, the last section discusses future research and provides a summary.</Paragraph>
<Paragraph position="7"> 4 This terminology was adopted from Rhetorical Structure Theory (Mann and Thompson 1983, 1988), discussed in Section 2. 5 Our notion of shared belief is similar to the notion of one-sided mutual belief (Clark and Marshall 1981). However, following Thomason (1990), a shared belief is merely represented in the conversational record as if it were mutually believed, although each participant need not actually believe it. 6 However, our model does not address the interesting question of under what conditions a direct answer should be given explicitly even when it is inferable from other parts of the response. For some related work on the function of redundant information, see Walker (1993).</Paragraph>
</Section>
</Paper>

