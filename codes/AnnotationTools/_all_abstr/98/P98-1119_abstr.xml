<?xml version="1.0" standalone="yes"?>

<Paper uid="P98-1119">
<Title>Automatic Acquisition of Language Model based on Head-Dependent Relation between Words</Title>
<Section position="1" start_page="0" end_page="0" type="abstr">
<SectionTitle>
Abstract
</SectionTitle>
<Paragraph position="0"> Language modeling is to associate a sequence of words with a priori probability, which is a key part of many natural language applications such as speech recognition and statistical machine translation. In this paper, we present a language modeling based on a kind of simple dependency grammar. The grammar consists of head-dependent relations between words and can be learned automatically from a raw corpus using the reestimation algorithm which is also introduced in this paper. Our experiments show that the proposed model performs better than n-gram models at 11% to 11.5~ reductions in test corpus entropy.</Paragraph>
</Section>
</Paper>

