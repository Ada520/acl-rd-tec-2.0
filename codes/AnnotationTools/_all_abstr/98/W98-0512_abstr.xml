<?xml version="1.0" standalone="yes"?>

<Paper uid="W98-0512">
<Title>I \\ - I Complements and Adjuncts in Dependency Grammar~arsing Emulated by a Constrained Context-Free Gramn~ar</Title>
<Section position="1" start_page="0" end_page="103" type="abstr">
<SectionTitle>
Abstract
</SectionTitle>
<Paragraph position="0"> Generalizing from efforts parsing natural language sentences using the grammar formalism, Dependency Grammar (DG) has been emulated by a context-free grammar (CFG) constrained by grammatical function annotation. Single-headedness and projectivity are assumed. This approach has the benefit of making general constraint-based context-free grammar parsing facilities available to DG analysis. This paper describes an experimental implementation of this approach using unification to realize grammatical function constraints imposed on a dependency structure backbone emulated by a context-flee grammar. Treating complements of a head word using subcategoHzation lists residing in the head word makes it possible to keep phrase-structure-rule-like mechanisms to the minimum. Adjuncts are treated with a syntactic mechanism that does not reside in the lexicon in this generally lexical approach to grammar.</Paragraph>
<Paragraph position="1"> Introduction The mathematical properties of Dependency Grammar (Tesniere (1959)) are studied by Gaifman (1965) and Hays (1964). Following their footsteps, Robinson (1970) formulates four axioms to govern the weU-formedness of  dependency structures: (a) One and only one element is independent; (b) All others depend directly on some element; (c) No element depends directly on more than one other;, (d) If A depends directly on B and some element C  intervenes between them (in linear order ofs~ing), then C depends directly on A or on B or some other intervening element.</Paragraph>
<Paragraph position="2"> These axioms require that all words should depend on only one word and that, arranging words in linear order, crossing of dependency links as in Fig.l should not be allowed.</Paragraph>
<Paragraph position="3"> Yuyanxue linguistics wo zhidao ta xihuan I know he likes Fig.! These are effectively the requirements of single-headedness and projectivity.</Paragraph>
<Paragraph position="4"> While there are some schools of DG that do not follow Robinson's axioms in their entirety (e.g. Hudson (1984, 1990), Melcuk (1988)), many computational linguists working on DG-based parsing have based their work on these assumptions (e.g. Hellwig (1986), Covington (1990)). DG parsing of Chinese have used statistical corpus-based algorithms (Huang et al. (1992), Yuan and Huang. (1992)), rule-based  they may or may not take word order into defined by Robinson's axioms, does have aspects consideration; but they all observe Robinson's that cannot be modelled elegantly by PSG. axioms in their entirety. They also label I depedency relations with grammatical functions 1 Representation of Dependency like subject and object.</Paragraph>
<Paragraph position="5"> Generalizing over DG-based parsing of The governor-dependent (head-modifier) I Chinese, Lai and Huang (1994) note that, taking relationship between words in an utterance can be linear word-order into consideration, this represented as for the Chinese sentence (from approach to DG can be emulated by a model YuanandHuang(1992) in Fig. 2: I having a context-free constituent component that / '~ is constrained by a grammatical function / component, very much in the spirit of the U constituent and functional structures of Lexical Functional Grammar (LFG, Bresnan ed. (1982)).</Paragraph>
<Paragraph position="6"> The syntactic dependency structure in this approach to DG is however different from context-free phrase structure in that non-lexical phrasal nodes are not allowed. As in LFG, the grammatical function structure, which provides the constraining mechanism, is mathematically a graph rather than a tree. This relieves the syntactic dependency component of any need to be multiple-headed and non-projective (Lai and Huang 1995). Following this approach, Lai and Huang (in press) describes a unification-based (Shieber (1986)) experimental parser adapted from the PATR parser in Gazdar and Mellish (1989). Control and simple semantic analysis are handled.</Paragraph>
<Paragraph position="7"> The present paper discusses issues of using a constrained CFG to emulate DG. Section 1 explains the implications of Robinson's axioms and describes Hays' CFG-like formulation of dependency rules. Section 2 formulates the &amp;quot;dependency rule with grammatical function annotation&amp;quot; model and describes its emulation with PATR. Section 3 discusses how the lexical orientation of DG motivates a proper distinction between complements subeategorized for by the head and adjuncts that are not, and describes how this can be accomplished in a constrained CFG emulation using subcategorization lists in the lexicon. A distinction between grammatical information residing and not residing in the lexicon is noted. Section 4 discusses the real nature of the constrained CFG emulation of DG.</Paragraph>
<Paragraph position="8"> Though DG can be usefully emulated by a constrained CFG model, the formalism, as least as Na ten zai gongyuan li that person in park inside Fig. 2 The main (or central) element, using Hays' (1964) terminology, of the sentence is zaL Its immediate dependants are ten and !i, which, in turn, have dependants of their own. This sentence can also be represented as in Fig. 3 (Tesniere's stemma): zai ten ii / na gongyuan Fig. 3 If we do not mangle up word order in the dependency structure of Fig. 3, it can be seen that it is equivalent to the tree structure in Fig. 2. Based on the work of Gaifman (1965), Hays (1964) proposes rules of the following form for the generation of dependency structures:  In Fig.4, (a) states that the governing auxiliary alphabet X has dependent A, B, C ..... H, Y ..... Z and that X itself (the governor) is situated between</Paragraph>
<Paragraph position="10"> occurs without any dependants. (c) says that X occurs without any governor, i.e. it is the main or I central element. Gaifman (1965) establishes that a Dependency Grammar obtained in this way is equivalent to a phrase structure grammar in the I sense that: - they have the same terminal alphabet; - for every string over that alphabet, I structure attributed by either every grammar corresponds to a structure attributed by the other.</Paragraph>
<Paragraph position="11"> I Robinson's (1970) four axioms (v. supra) license the same kinds of dependency structures I as Hays' rules. Unlike these rules, they do not contain unnecessary stipulation involving linear word order. It is easy to see that the third axiom is I a requirement of single-headedness. As for the fourth axiom, consider Fig. 5: B' ! Fig. 5 The axiom stipulates that the governor of C must be located between A and B (which are themselves possible governors). Seen in the Baysian cast, this effectively requires that the link between C and its governor should not cross the lines AB' and BB'. This is thus a requirement of projectivity.</Paragraph>
</Section>
</Paper>

