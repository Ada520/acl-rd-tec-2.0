<?xml version="1.0" standalone="yes"?>

<Paper uid="J03-4004">
<Title>Adjectives Using Automatically Acquired Selectional Preferences</Title>
<Section position="2" start_page="0" end_page="640" type="abstr">
<SectionTitle>
1. Introduction
</SectionTitle>
<Paragraph position="0"> Although selectional preferences are a possible knowledge source in an automatic word sense disambiguation (WDS) system, they are not a panacea. One problem is coverage: Most previous work has focused on acquiring selectional preferences for verbs and applying them to disambiguate nouns occurring at subject and direct object slots (Ribas 1995; McCarthy 1997; Abney and Light 1999; Ciaramita and Johnson 2000; Stevenson and Wilks 2001). In normal running text, however, a large proportion of word tokens do not fall at these slots. There has been some work looking at other slots (Resnik 1997), and on using nominal arguments as disambiguators for verbs (Federici, Montemagni, and Pirrelli 1999; Agirre and Martinez 2001), but the problem of coverage remains. Selectional preferences can be used for WSD in combination with other knowledge sources (Stevenson and Wilks 2001), but there is a need to ascertain when they work well so that they can be utilized to their full advantage. This article is aimed at quantifying the disambiguation performance of automatically acquired selectional preferences in regard to nouns, verbs, and adjectives with respect to a standard test corpus and evaluation setup (SENSEVAL-2) and to identify strengths and weaknesses. Although there is clearly a limit to coverage using preferences alone, because preferences are acquired only with respect to specific grammatical roles, we show that when dealing with running text, rather than isolated examples, coverage can be increased at little cost in accuracy by using the one-sense-per-discourse heuristic.</Paragraph>
<Paragraph position="1"> [?] Department of Informatics, University of Sussex, Brighton BN1 9QH, UK. E-mail: {dianam,  Computational Linguistics Volume 29, Number 4 We acquire selectional preferences as probability distributions over the Word-Net (Fellbaum 1998) noun hyponym hierarchy. The probability distributions are conditioned on a verb or adjective class and a grammatical relationship. A noun is disambiguated by using the preferences to give probability estimates for each of its senses in WordNet, that is, for WordNet synsets. Verbs and adjectives are disambiguated by using the probability distributions and Bayes' rule to obtain an estimate of the probability of the adjective or verb class, given the noun and the grammatical relationship. Previously, we evaluated noun and verb disambiguation on the English all-words task in the SENSEVAL-2 exercise (Cotton et al. 2001). We now present results also using preferences for adjectives, again evaluated on the SENSEVAL-2 test corpus (but carried out after the formal evaluation deadline). The results are encouraging, given that this method does not rely for training on any hand-tagged data or frequency distributions derived from such data. Although a modest amount of English sense-tagged data is available, we nevertheless believe it is important to investigate methods that do not require such data, because there will be languages or texts for which sense-tagged data for a given word is not available or relevant.</Paragraph>
</Section>
</Paper>

