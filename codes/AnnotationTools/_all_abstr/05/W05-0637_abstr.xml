<?xml version="1.0" standalone="yes"?>

<Paper uid="W05-0637">
<Title>Applying spelling error correction techniques for improving semantic role labelling</Title>
<Section position="2" start_page="0" end_page="0" type="abstr">
<SectionTitle>
1 Introduction
</SectionTitle>
<Paragraph position="0"> This paper describes our approach to the CoNLL-2005 shared task: semantic role labelling. We do many of the obvious things that can be found in the other submissions as well. We use syntactic trees for deriving instances, partly at the constituent level and partly at the word level. On both levels we edit the data down to only the predicted positive cases of verb-constituent or verb-word pairs exhibiting a verb-argument relation, and we train two next-level classifiers that assign the appropriate labels to the positively classified cases. Each classifier is trained on data in which the features have been selected to optimize generalization performance on the particular task. We apply different machine learning algorithms and combine their predictions.</Paragraph>
<Paragraph position="1"> As a novel addition, we designed an automatically trained post-processing module that attempts to correct some of the errors made by the base system.</Paragraph>
<Paragraph position="2"> To this purpose we borrowed Levenshtein-distance-based correction, a method from spelling error correction to repair mistakes in sequences of labels. We adapted the method to our needs and applied it for improving semantic role labelling output. This paper presents the results of our approach.</Paragraph>
</Section>
</Paper>

