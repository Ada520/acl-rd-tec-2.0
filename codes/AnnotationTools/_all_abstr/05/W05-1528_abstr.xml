<?xml version="1.0" standalone="yes"?>

<Paper uid="W05-1528">
<Title>k-NN for Local Probability Estimation in Generative Parsing Models</Title>
<Section position="2" start_page="0" end_page="0" type="abstr">
<SectionTitle>
Abstract
</SectionTitle>
<Paragraph position="0"> We describe a history-based generative parsing model which uses a k-nearest neighbour (k-NN) technique to estimate the model's parameters. Taking the output of a base n-best parser we use our model to re-estimate the log probability of each parse tree in the n-best list for sentences from the Penn Wall Street Journal treebank. By further decomposing the local probability distributions of the base model, enriching the set of conditioning features used to estimate the model's parameters, and using k-NN as opposed to the Witten-Bell estimation of the base model, we achieve an f-score of 89.2%, representing a 4% relative decrease in f-score error over the 1-best output of the base parser.</Paragraph>
</Section>
</Paper>

