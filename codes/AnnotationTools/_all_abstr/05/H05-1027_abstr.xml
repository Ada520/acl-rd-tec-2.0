<?xml version="1.0" standalone="yes"?>

<Paper uid="H05-1027">
<Title></Title>
<Section position="2" start_page="1" end_page="1" type="abstr">
<SectionTitle>
Abstract
</SectionTitle>
<Paragraph position="0"> This paper proposes a new discriminative training method, called minimum sample risk (MSR), of estimating parameters of language models for text input. While most existing discriminative training methods use a loss function that can be optimized easily but approaches only approximately to the objective of minimum error rate, MSR minimizes the training error directly using a heuristic training procedure. Evaluations on the task of Japanese text input show that MSR can handle a large number of features and training samples; it significantly outperforms a regular trigram model trained using maximum likelihood estimation, and it also out-performs the two widely applied discriminative methods, the boosting and the perceptron algorithms, by a small but statistically significant margin.</Paragraph>
</Section>
</Paper>

