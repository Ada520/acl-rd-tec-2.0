<?xml version="1.0" standalone="yes"?>

<Paper uid="J83-2002">
<Title>Treating Coordination in Logic Grammars</Title>
<Section position="2" start_page="0" end_page="0" type="abstr">
<SectionTitle>
1. Introduction
</SectionTitle>
<Paragraph position="0"> Since the development of the Prolog programming language (Colmerauer 1973; Roussel 1975), logic programming (Kowalski 1974, 1979; Van Emden 1975) has been applied in many different fields. In natural language processing, useful grammar formalisms have been developed and incorporated in Prolog: metamorphosis grammars, due to Colmerauer (1978), and extraposition grammars, defined by F. Pereira (1981); definite clause grammars (Pereira and Warren 1980) are a special case of metamorphosis grammars.</Paragraph>
<Paragraph position="1"> The first sizable application of logic grammars was a Spanish/French-consultable data base system by Dahl (1977, 1981), which was later adapted to Portuguese l Visiting in the Computer Science Department, University of Kentucky, during part of this research. Work partially supported by Canadian NSERC Grant A2436 and Simon Fraser P.R. Grant 42406, 2 Current address: IBM Thomas J. Watson Research Center, P.O. Box 218, Yorktown Heights, NY 10598.</Paragraph>
<Paragraph position="2"> by L. Pereira and H. Coelho and to English by F.</Paragraph>
<Paragraph position="3"> Pereira and D. Warren. Coelho (1979) developed a consulting system in Portuguese for library service, and F. Pereira and D. Warren (1980) developed a sizable English data base query system with facilities for query optimization. McCord (1982, 1981) presented ideas for syntactic analysis and semantic interpretation in logic grammars, with application to English grammar; some of these ideas are used in our work described here.</Paragraph>
<Paragraph position="4"> Coordination (grammatical construction with the conjunctions 'and', 'or', 'but') has long been one of the most difficult natural language phenomena to handle, because it can involve such a wide range of grammatical constituents (or non-constituent fragments), and ellipsis (or reduction) can occur in the items conjoined. In most grammatical frameworks, the grammar writer desiring to handle coordination can get by reasonably well by writing enough specific rules involving particular grammatical categories; but it appears that a proper and general treatment must recognize coordina-Copyright 1983 by the Association for Computational Linguistics. Permission to copy without fee all or part of this material is granted provided that the copies are not made for direct commercial advantage and the Journal reference and this copyright notice are included on the first page. To copy otherwise, or to republish, requires a fee and/or specific permission. 0362-613X/83/020069-23 $03.00 American Journal of Computational Linguistics, Volume 9, Number 2, April-June 1983 69 Veronica Dahl and Michael C. McCord Treating Coordination in Logic Grammars tion as a &amp;quot;metagrammatical&amp;quot; construction, in the sense that metarules, general system operations, or &amp;quot;secondpass&amp;quot; operations such as transformations, are needed for its formulation.</Paragraph>
<Paragraph position="5"> Perhaps the most general and powerful metagrammatical device for handling coordination in computational linguistics has been the SYSCONJ facility for augmented transition networks (ATNs) (Woods 1973; Bates 1978). The ATN interpreter with this facility built into it can take an ATN that does not itself mention conjunctions at all, and will parse reduced coordinate constructions, which are of the form A X and Y B, for example, John drove his car through and A X completely demolished a plate glass window.</Paragraph>
<Paragraph position="6"> Y B where the unreduced deep structure corresponds to A X B and A Y B.</Paragraph>
<Paragraph position="7"> The result of the parse is this unreduced structure.</Paragraph>
<Paragraph position="8"> SYSCONJ accomplishes this by treating the conjunction as an interruption which causes the parser to back up in its history of the parse. Before backing up, the current configuration (immediately before the interruption) is suspended for later merging. The backing up is done to a point when the string X was being parsed (this defines X), and with this configuration the string Y is parsed. The parsing of Y stops when a configuration is reached that can be merged with the suspended configuration, whereupon B is parsed. The choices made in this process can be deterministic or non-deterministic, and can be guided by syntactic or semantic heuristics.</Paragraph>
<Paragraph position="9"> There are some problems with SYSCONJ, however.</Paragraph>
<Paragraph position="10"> It suffers from inefficiency, due to the combinatorial explosion from all the choices it makes. Because of this inefficiency, it in fact has not been used to a great extent in ATN parsing. Another problem is that it does not handle embedded complex structures. Furthermore, it is not clear to us that SYSCONJ offers a good basis for handling the scoping problems that arise for semantic interpretation when conjunctions interact with quantifiers (and other modifiers) in the sentence.</Paragraph>
<Paragraph position="11"> This latter problem is discussed in detail below.</Paragraph>
<Paragraph position="12"> In this paper we present a system for handling co-ordination in logic grammars. The system consists of three things: (1) a new formalism for logic grammars, which we call modifier structure grammars (MSGs), (2) an interpreter (or parser) for MSGs that takes all the responsibility for the syntactic aspects of co-ordination (as with SYSCONJ), and (3) a semantic interpretation component that produces logical forms from the output of the parser and deals with scoping problems for coordination.</Paragraph>
<Paragraph position="13"> The whole system is implemented in Prolog-10 (Pereira, Pereira, and Warren 1978).</Paragraph>
<Paragraph position="14"> Coordination has of course received some treatment in standard logic grammars by the writing of specific grammar rules. The most extensive treatment of this sort that we know of is in Pereira et al. (1982), which also deals with ellipsis. However, we are aware of no general, metagrammatical treatment of coordination in logic grammars previous to ours.</Paragraph>
<Paragraph position="15"> Modifier structure grammars, described in detail in Section 2, are true logic grammars, in that they can be translated (compiled) directly into Horn clause systems, the program format for Prolog. In fact, the treatment of extraposition in MSGs is based on F.</Paragraph>
<Paragraph position="16"> Pereira's (1981) extraposition grammars (XGs), and MSGs can be compiled into XGs (which in turn can be compiled into Horn clause systems). A new element in MSGs is that the formation of analysis structures of sentences has been made largely implicit in the grammar formalism. For previous logic grammar formalisms, the formation of analyses is entirely the responsibility of the grammar writer. Compiling MSGs into XGs consists in making this formation of analyses explicit.</Paragraph>
<Paragraph position="17"> Although MSGs can be compiled into XGs, it seems difficult to do this in a way that treats coordination automatically (it appears to require more metalogical facilities than are currently available in Prolog systems). Therefore, we are using an interpreter for MSGs (written in Prolog).</Paragraph>
<Paragraph position="18"> For MSGs, the analysis structure associated (by the sYstem) with a sentence is called the modifier structure (MS) of the sentence. This structure can be considered an annotated phrase structure tree, and in fact the name &amp;quot;modifier structure grammar&amp;quot; is intended to be parallel to &amp;quot;phrase structure grammar&amp;quot;. If extraposition and coordination are neglected, there is a context-free phrase structure grammar underlying an MSG; and the MS trees are indeed derivation trees for this underlying grammar, but with extra information attached to the nodes.</Paragraph>
<Paragraph position="19"> In an MS tree, each node contains not only syntactic information but also a term called a semantic item (supplied in the grammar), which determines the node's contribution to the logical form of the sentence. This contribution is for the node alone, and does not refer to the daughters of the node, as in the approach of Gazdar (1981). Through their semantic items, the daughters of a node act as modifiers of the node, in a fairly traditional sense made precise below - hence the term &amp;quot;modifier structure&amp;quot;.</Paragraph>
<Paragraph position="20"> The notion of modifier structure used here and the semantic interpretation component, which depends on it, are much the same as in previous work by McCord 70 American Journal of Computational Linguistics, Volume 9, Number 2, April-June 1983 Veronica Dahl and Michael C. McCord Treating Coordination in Logic Grammars (1982, 1981), especially the latter paper. But new elements are the notion of MSG (making modifier structure implicit in the grammar), the MSG interpreter, with its treatment of coordination, and the specific rules for semantic interpretation of coordination.</Paragraph>
<Paragraph position="21"> The MSG interpreter is described in Section 3. As indicated above, the interpreter completely handles the syntax of coordination. The MSG grammar itself should not mention conjunctions at all. The interpreter has a general facility for treating certain words as demons (cf. Winograd 1972), and conjunctions are handled in this way. When a conjunction demon appears in a sentence A X conj Y B, a process is set off which in outline is like SYSCONJ, in that backing up is done in the parse history in order to parse Y parallel to X, and B is parsed by merger with the state interrupted by the conjunction. However, our system has the following interesting features: (1) The MSG interpreter manipulates stacks in such a way that embedded coordination (and coordination of more than two elements) and interactions with extraposition are handled. (Examples are given in the Appendix.) (2) The interpreter produces a modifier structure for the sentence A X conj Y B which remains close to the surface form, as opposed to the unreduced structure A X B conj A Y B (but it does show all the pertinent semantic relations through unification of variables). Not expanding to the unreduced form is important for keeping the modifier relationships straight, in particular, getting the right quantifier scoping. Our system analyzes the sentence null Each man drove a car through and completely demolished a glass window, producing the logical form each(X,man(X),exists(Y,car(Y), exists(Z,glass(Z)&amp;window(Z),</Paragraph>
<Paragraph position="23"> This logical form would be difficult to recover from the unreduced structure, because the quantified noun phrases are repeated in the unreduced structure, and the logical form that corresponds most naturally to the unreduced structure is not logically equivalent to the  above logical form.</Paragraph>
<Paragraph position="24"> (3) In general, the use of modifier structures and the associated semantic interpretation component permits a good treatment of scoping problems involving coordination. Examples are given below.</Paragraph>
<Paragraph position="25"> (4) The system seems reasonably efficient. For example, the analysis of the example sentence under (2) above (including syntactic analysis and semantic  interpretation) was done in 177 milliseconds. The reader can examine analysis times for other examples in the Appendix. One reason for the efficiency is just that the system is formulated as a logic programming system, and especially that it uses Prolog-10, with its compiler. Another reason presumably lies in the details of the MSG interpreter. For example, the interpreter does not save the complete history of the parse, so that the backing up necessary for coordination does not examine as much.</Paragraph>
<Paragraph position="26"> (5) The code for the system seems short, and most of it is listed in this paper.</Paragraph>
<Paragraph position="27"> The semantic interpretation component is described in Section 4, but not in complete detail since it is taken in the main from McCord (1982, 1981). Emphasis is on the new aspects involving semantic interpretation of coordinate modifiers.</Paragraph>
<Paragraph position="28"> Semantic interpretation of a modifier structure tree is done in two stages. The first stage, called reshaping, deals heuristically with the well-known scoping problem, which arises because of the discrepancies that can exist between (surface) syntactic relations and intended semantic relations. Reshaping is a transformation of the syntactic MS tree into another MS tree with the (hopefully) correct modifier relations. The second stage takes the reshaped tree and translates it into logical form. The modifiers actually do their work of modification in this second stage, through their semantic items.</Paragraph>
<Paragraph position="29"> As an example of the effects of reshaping on coordinate structures involving quantifiers, the sentence Each man and each woman ate an apple is given the logical form</Paragraph>
<Paragraph position="31"> whereas the sentence A man and a woman sat at each table is given the form each(Y,table(Y), exists(X,man(X),sat_at(X,Y)) &amp; exists(X,woman(X),sat_at (X,Y))). Section 5 of the paper presents a short discussion of possible improvements for the system, and Section 6 consists of concluding remarks. The Appendix to the paper contains a listing of most of the system, a sample MSG, and sample parses. The reader may wish to examine the sample parses at this point.</Paragraph>
<Paragraph position="32"> American Journal of Computational Linguistics, Volume 9, Number 2, April-June 1983 71 Veronica Dahl and Mlichael C. IVlcCord Treating Coordination in Logic Grammars</Paragraph>
</Section>
</Paper>

