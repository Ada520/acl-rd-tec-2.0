<?xml version="1.0" standalone="yes"?>

<Paper uid="E06-3001">
<Title>What's There to Talk About? A Multi-Modal Model of Referring Behavior in the Presence of Shared Visual Information</Title>
<Section position="1" start_page="0" end_page="0" type="abstr">
<SectionTitle>
Abstract
</SectionTitle>
<Paragraph position="0"> This paper describes the development of a rule-based computational model that describes how a feature-based representation of shared visual information combines with linguistic cues to enable effective reference resolution. This work explores a language-only model, a visual-only model, and an integrated model of reference resolution and applies them to a corpus of transcribed task-oriented spoken dialogues. Preliminary results from a corpus-based analysis suggest that integrating information from a shared visual environment can improve the performance and quality of existing discourse-based models of reference resolution.</Paragraph>
</Section>
</Paper>

