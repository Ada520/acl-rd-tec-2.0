<?xml version="1.0" standalone="yes"?>

<Paper uid="W06-1666">
<Title>Loss Minimization in Parse Reranking</Title>
<Section position="2" start_page="0" end_page="0" type="abstr">
<SectionTitle>
Abstract
</SectionTitle>
<Paragraph position="0"> We propose a general method for reranker construction which targets choosing the candidate with the least expected loss, rather than the most probable candidate.</Paragraph>
<Paragraph position="1"> Different approaches to expected loss approximation are considered, including estimating from the probabilistic model used to generate the candidates, estimating from a discriminative model trained to rerank the candidates, and learning to approximate the expected loss. The proposed methods are applied to the parse reranking task, with various baseline models, achieving significant improvement both over the probabilistic models and the discriminative rerankers. When a neural network parser is used as the probabilistic model and the Voted Perceptron algorithm with data-defined kernels as the learning algorithm, the loss minimization model achieves 90.0% labeled constituents F1 score on the standard WSJ parsing task.</Paragraph>
</Section>
</Paper>

