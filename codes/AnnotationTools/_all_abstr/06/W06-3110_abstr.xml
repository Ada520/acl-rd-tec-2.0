<?xml version="1.0" standalone="yes"?>

<Paper uid="W06-3110">
<Title>N-Gram Posterior Probabilities for Statistical Machine Translation</Title>
<Section position="1" start_page="0" end_page="0" type="abstr">
<SectionTitle>
Abstract
</SectionTitle>
<Paragraph position="0"> Word posterior probabilities are a common approach for confidence estimation in automatic speech recognition and machine translation. We will generalize this idea and introduce n-gram posterior probabilities and show how these can be used to improve translation quality. Additionally, we will introduce a sentence length model based on posterior probabilities.</Paragraph>
<Paragraph position="1"> We will show significant improvements on the Chinese-English NIST task. The absolute improvements of the BLEU score is between 1.1% and 1.6%.</Paragraph>
</Section>
</Paper>

