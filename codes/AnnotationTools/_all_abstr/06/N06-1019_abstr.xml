<?xml version="1.0" standalone="yes"?>

<Paper uid="N06-1019">
<Title>Partial Training for a Lexicalized-Grammar Parser</Title>
<Section position="1" start_page="0" end_page="0" type="abstr">
<SectionTitle>
Abstract
</SectionTitle>
<Paragraph position="0"> We propose a solution to the annotation bottleneck for statistical parsing, by exploiting the lexicalized nature of Combinatory Categorial Grammar (CCG). The parsing model uses predicate-argument dependencies for training, which are derived from sequences of CCG lexical categories rather than full derivations. A simple method is used for extracting dependencies from lexical category sequences, resulting in high precision, yet incomplete and noisy data. The dependency parsing model of Clark and Curran (2004b) is extended to exploit this partial training data. Remarkably, the accuracy of the parser trained on data derived from category sequences alone is only 1.3% worse in terms of F-score than the parser trained on complete dependency structures.</Paragraph>
</Section>
</Paper>

