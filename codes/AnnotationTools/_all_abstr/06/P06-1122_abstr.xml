<?xml version="1.0" standalone="yes"?>

<Paper uid="P06-1122">
<Title>Modelling lexical redundancy for machine translation</Title>
<Section position="2" start_page="0" end_page="0" type="abstr">
<SectionTitle>
Abstract
</SectionTitle>
<Paragraph position="0"> Certain distinctions made in the lexicon of one language may be redundant when translating into another language. We quantify redundancy among source types by the similarity of their distributions over target types. We propose a language-independent framework for minimising lexical redundancy that can be optimised directly from parallel text. Optimisation of the source lexicon for a given target language is viewed as model selection over a set of cluster-based translation models.</Paragraph>
<Paragraph position="1"> Redundantdistinctionsbetweentypesmay exhibit monolingual regularities, for example, inflexion patterns. We define a prior over model structure using a Markov random field and learn features over sets of monolingual types that are predictive of bilingual redundancy. The prior makes model selection more robust without the  needforlanguage-specificassumptionsregarding redundancy. Using these models in a phrase-based SMT system, we show significant improvements in translation quality for certain language pairs.</Paragraph>
</Section>
</Paper>

