<?xml version="1.0" standalone="yes"?>

<Paper uid="C67-1006">
<Title>SUMMARY - Syntactic and Semantic Problems in Automatic Sentence</Title>
<Section position="1" start_page="0" end_page="0" type="abstr">
<SectionTitle>
SYNTACTIC AND SEMANTIC PROBLEMS IN AUTOMATIC SENTENCE GENERATION, ~ ~ O~#/
</SectionTitle>
<Paragraph position="0"> Kenneth E. Harper ~/v{~/..~.-.~ A program for automatic sentence generation (ASG) has been developed~cJ/~,.r in the linguistic group at The RAND Corporation, as a device for study- /~ / ing selected problems in syntax and distributional semantics. The general purpose of the study is to test certain linguistic assumptions by experimentation:&amp;quot; what is the result when a computer program &amp;quot;composes&amp;quot; sentences on the basis of these assumptions? The assumptions, and their implementation in the computer program, are subject to modification, as deficiencies are observed in the output sentences. This trial-and-error procedure is presently at an early stage of development; the present paper is a brief, non-technical description of the procedure, and a report on some of the initial problems encountered, together with tentative solutions. The ultimate goal of the research is the generation of &amp;quot;paragraphs&amp;quot; (meaningful strings of sentences) as a contribution towards automatic abstracting.</Paragraph>
<Paragraph position="1"> i. The Sentence Generation Routine The ASG program operates with Russian language materials, for the simple reason that the kind of data on which the linguistic assumptions are based is available only for Russian. The data is derived from the corpus of Russian physics text processed at The RAND Corporation (References i, 2). In effect, the program described here deals with a sub-set of the Russian language found in these physics texts.</Paragraph>
<Paragraph position="2"> The program may be said to consist of three parts: a glossary of words, a granlnar, and a program for synthesizing sentences.</Paragraph>
<Paragraph position="3"> (i) The glossary is merely a list of 550 Russian words on magnetic tape; each entry consists of a &amp;quot;word number&amp;quot; (the word-identification number in the RAND physics glossary), (Reference 3) and a representative Russian form (not necessarily the canonical form). The glossary comes into operation only at the end of the sentence generation routine. Generally, the words in the glossary are used in a single sense in physics texts.</Paragraph>
<Paragraph position="4"> (ii) The~r~ar employed is a simplified dependency grannnar for Russian. Its essential feature is that it is word-specific: each word in the glossary is provided a list of words with which it may combine in a dependency or governor relationship. The basic principle is that syntactic cooccurrence (e.g., the pairing of a given noun with a given adjective) is allowed only if this pairing is attested in the previously processed physics text. (An exception is made in the pairing of members of Semantic Classes, as explained below.) null The following information, available for each word in the glossary, may be said to constitute the grammar:  i) Word number 2) Part-of-speech code. Six such codes are used: VT (transitive verb), Vl (intransitive verb), N (noun), A (adjective), DV (adverb), and DS (sentence adverb). A word may bear only one such code.</Paragraph>
<Paragraph position="5"> 3) Semantic Class code (SC). Twenty such classes are recognized; all are distributionally formed. (References 4, 5) 4) Set of governing probabilities 5) Set of dependent probabilities 6) Coordinate probability - I 7) Li~t of word nmnbers of governors 8) List of word numbers of dependents 9) List of word numbers of coordinates  Table i illustrates the meanlngof governing probabilities. Reading across the top line in the table, we see that each VT has a probability of Pl &amp;quot;of governing some noun as subject and a probability of i of governing some noun as object. The VT has probabilities of P~ and Pq of governing an adverb and a sentence adverb respectively, an~ a pro: bability of 0 of governing anything else. The table shows also that each VI must govern a noun as subject, and governs a DV and DS with probabilities PA and P. respectively; each noun governs another noun or an adjective-with p~obabilities P~ and P.; a DS has a probability of i of governing a noun; adjectives-and adverbs never govern.</Paragraph>
<Paragraph position="6"> Table 2 shows the meaning of dependent probabilities; here, reading across, the various probabilities of being governed by other parts-of-speech are shown for nouns, adjectives, adverbs, and sentence adverbs; verbs do not have governors.</Paragraph>
<Paragraph position="7"> The sets of governing probabilities for a word are associated with independent situations. For example, a transitive verb governs a noun as subject, a noun as object, an adverb and a sentence adverb independently. Therefore, in sentence generation, the decision to select a dependent type will be made without regard to any dependent types already selected for that governor. This is not the case, however, when selecting a governor for a particular word. The possibilities here are dependent events. An adverb, for example, must be governed by either a transitive or intransitive verb. Thus, the set of probabilities for each word will add to one.</Paragraph>
<Paragraph position="8"> Probabilities for coordination are assigned for relatively few words. Since coordinate conjunctions are not represented as a word class, the assignment of a Russian form for &amp;quot;and&amp;quot; and &amp;quot;or&amp;quot; will be generated by the program (rather than by the glossary) in the sentence output stage. As previously mentioned, each word is accompanied by a list of the word nombers that may function as its governors and dependents. Generally, these dependency pairs have been attested in physics text. However, a Semantic Class may also function as a word's governor or dependent; when this happens, the program is free to choose randomly any member of the SC in building the dependency pair. Many such pairs will not have been attested in text; the purpose here is to test the adequacy of the Semantic Classes in word combination. A complete list of the SC's cannot be given here; examples are (a) nouns that name physical properties (&amp;quot;height,&amp;quot; &amp;quot;weight&amp;quot;), ~) verbs and nouns referring to a quantitative change (&amp;quot;to increase,&amp;quot; &amp;quot;change&amp;quot;), and (c) the names of physical particles (&amp;quot;atom,&amp;quot; &amp;quot;proton&amp;quot;). The classes, and their members, are purely experimental and are subject to modification. (iii) The ~rogram for ASG (written in MAP for the IBM 7044) is intricately bound up with the grarmnar, but for purposes of discussion we may consider it separately. Essentially, the program has three functions. First, it restructures the grammar, in order to access Itwlth minimal search time. (The grau~ar and the program are maintained in core storage.) Secondly, the program generates sentences; beginning</Paragraph>
<Paragraph position="10"> structure until a terminal point is reached. In the process, the algorithm provides that decisions of two kinds will be made at each node: (~ shall a dependent (or governor) be chosen for the word at this node, and (ii) if so, which word shall be chosen to complete the dependency pair? The grammar supplies the basic information necessary for making decisions; a pseudo-random number generator with uniform distribution is used in conjunction with the grammar when a choice exists. Finally, the program prints out the generated sentences in a fixed format.</Paragraph>
<Paragraph position="11"> In their preliminary form, the sentences are merely strings of word numbers, together with associated data; glossary lookup then provides the transliterated Russian form associated with each word number. At present, the problem of morphology is bypassed: no attempt is made to supply the correct inflection of words in the sentence. The information necessary to carry out an inflection routine is available for nouns and adjectives (i.e., inflection for case and number); for verbs, person and number are specified, but tense is not. In the sentences discussed below, correct forms for nouns, verbs and adjectives have been supplied for reasons of clarity.</Paragraph>
<Paragraph position="12"> An example will perhaps serve to clarify the operation of the ASG program. In a greatly simplified way, the algorithm proceeds as follows. null  (i) A starting point is chosen for the sentence. Possible starting points are transitive verb (VT), intransitive verb (VI), and noun (N). By random selection, VI is chosen for this sentence.</Paragraph>
<Paragraph position="13"> (2) Randomly, a particular VI is chosen from the list of Vl's in the glossary. Here, we assume that word number 56410 is chosen.</Paragraph>
<Paragraph position="14"> (3) The possible dependent types of a VI are considered. (According to the gran~nar, verbs do not have governors, so that only dependents need be considered.) (3.1) The grammar specifies that a VI must have a subject (the probability P is one for this pairing). The list of dependents serving as subject for word number 56410 is consulted, and an individual word is randomly chosen: word nomber 34550.</Paragraph>
<Paragraph position="15"> (3.2) A Vl may have an adverb (DV) as dependent. For the verb in our sentence, the probability for this event is found to be .5. We assume that in this sentence the decision is made that a DV will be selected. The list of dependent DV's for word number 56410 is consuited, and an individual adverb is randomly selected: word number 14090.</Paragraph>
<Paragraph position="16"> (3.3) A VI may have a sentence adverb (DS) as a dependent. For our particular verb, the probability for this event is found to be .i.</Paragraph>
<Paragraph position="17"> We assume that a decision in made not to select a DS dependent.</Paragraph>
<Paragraph position="18"> (4) Next, the dependents of the dependents of the verb are considered, but only with respect to their possible dependents (i.e., working down the dependency tree structure).</Paragraph>
<Paragraph position="19"> (4.1) The noun chosen as subject (word 34550, from 3.1 above) may have various dependents, with varying probabilities. Each of these is considered in turn. For sake of brevity, we assume that only one  -4is chosen in our ss~nple sentence: an adjective. A particular adjective is randomly selected from the list of dependents for the noun: word number 63610.</Paragraph>
<Paragraph position="20"> (5) The adverb selected in 3.2 above has no dependents, according  to the grammar, nor does the adjective selected in 4.1. At this point, the downward search for dependents is terminated, and the sentence is considered complete.</Paragraph>
<Paragraph position="21"> In form, the sentence is at this point a string of word numbers on a tape: 56410, 34550, 14090, 63610. Attached to each word n~nber is data about its function in the sentence, its governor, the order in which it was selected, and, for nouns, an indication of grammatical number. Glossary lookup is then performed on this tape, and the transliterated Russian forms are printed out: uvellcennoe otnosenle zametna ~ta.</Paragraph>
<Paragraph position="22"> If fixed rules relating to word order and morphology are applied to to this string of forms, the sentence emerges as: Eto otnosenie zametno uveli~ivaetsja.</Paragraph>
<Paragraph position="23"> This ratio increases noticeably.</Paragraph>
<Paragraph position="24"> The foregoing is a drastically abbreviated description of the main steps in the ASG program. Sentences are presently generated at the rate of three per second; the addition of programming rules to account for morphology and word order would increase this time by an estimated ten percent. The program may, then, be considered as a practical, operational tool for research.</Paragraph>
<Paragraph position="25"> ~. Discussion of Generated Sentences At the present stage of development, the ASG program produces isolated sentences of varying degrees of complexity and ~fcorreetness.&amp;quot; Since words in the glossary are limited in usage to one sense, and since semantic controls are guaranteed at least over pairs of words, a large number of sentences are quite acceptable. (The development of a context into which such sentences can be placed is, naturally, a far more difficult programming task.) The following are examples of ~freasonable&amp;quot; sentences.</Paragraph>
<Paragraph position="26"> (i) Fejnman vy~islil integraly, s cel'ju opredelenija massy.</Paragraph>
<Paragraph position="27"> Feynman calculated the integrals in order to determine the mass.</Paragraph>
<Paragraph position="28">  (2) Re~enie zada~ predlagaetsja v nastoja~ej stat'e.</Paragraph>
<Paragraph position="29"> A solution of the problems is proposed in the present article.</Paragraph>
<Paragraph position="30"> (3) Ob~mkristallov izbyto~nogo serebra bystro umen'~aetsja.</Paragraph>
<Paragraph position="31"> The volume of the crystals of excess silver rapidly decreases.</Paragraph>
<Paragraph position="32"> (4) Vozmo~nost' sil'nogo vzaimodejstvija tela vne~nego &amp;quot; istocnika privlekaet interes.</Paragraph>
<Paragraph position="33">  The possibility of the strong interaction of the body of the internal source is interesting.</Paragraph>
<Paragraph position="34"> Sentence (4) illustrates the approximate limit in number of levels  -5(six) for &amp;quot;reasonable&amp;quot; sentences in the present system. Additional levels can easily be generated, but only through the process of annexing genitive noun modifiers (i.e., English &amp;quot;of&amp;quot; phrases). Very few sentences have been generated with more than six levels, principally because of the drastically reduced probabilities of noun complementatlon at lower levels in the tree. Thus, most sentences are short , The chief obstacle to increasing sentence length (and complexity) is, however, the absence in the grannnar of provisions for subordinate and coordinate clauses. Also inhibiting, from this point of view, isthe absence of participles, prepositional phrases (beyond those used as adverbs), and pronouns. The price for adding any of these grammatical categories is increased complexity in the program. In an experimental situation, brevity and stylistic monotony can be tolerated.</Paragraph>
<Paragraph position="35"> Deficiencies in the generated sentences are of two main types: syntactic and semantic. Problems in both areas will be illustrated, although the line of demarcation is so~aetimes difficult to draw. Syntactic problems are chiefly the result of inadequate complementa g tion of nouns by adjectives or other nouns. It will be recalled that the gran~nar specifies for each noun the probability of its modification by an adjective or a genitive noun. These probabilities are assigned on the basis of the noun's behavior in text (Refernce 6). Since P is normally less than one for both kinds of modification, a given noun may frequently appear in a generated sentence without  Formulae of the t.zp_~ are used.</Paragraph>
<Paragraph position="36"> Razrjad issledovan pri ras~ete.</Paragraph>
<Paragraph position="37"> The charge was studied in calculating.</Paragraph>
<Paragraph position="38"> . . Proverka daet metod polucen13a atoma.</Paragraph>
<Paragraph position="39"> Verification gives a method for obtaining the atom.</Paragraph>
<Paragraph position="40"> In (5), the noun phrase, &amp;quot;theories of the problems,&amp;quot; appears to be ill-formed; the difficulty may not really be syntactic, since in an appropriate context the phrase may be nothing more than an instance of ellipsis. Nonetheless, specificity as to &amp;quot;what kind of problems&amp;quot; should be provided in the given sentence, or in preceding sentences. The tmanodified use of &amp;quot;type&amp;quot; in sentence (6) is more difficult to justify on the basis of ellipsis; our tentative solution is to __require either an adjective or noun modifier for words like &amp;quot;type,&amp;quot; &amp;quot;kind,&amp;quot; etc. (A modification in the program is necessitated here, since at present the selection of adjective and noun dependents is made independently.) The nouns in (7) and (8) are strongly verbal, and appear to be deficient in complementation. This is particularly true of &amp;quot;ras~ete&amp;quot; in (7), translated with the &amp;quot;-ing&amp;quot; form because of its verbal usage with the sentence adverb, &amp;quot;pri.&amp;quot; It should be said that all sentence adverbs in our grammar have the property of conferring a verbal function upon noun dependents. (This is, of course, a very limited use</Paragraph>
<Paragraph position="42"> of sentence modifiers.) In order to maintain consistency inthe grammar, it is clear that the program should be modified: the probability that a given noun will govern a genitive noun should equal one when the noun is itself governed by ~ sentence adverb.</Paragraph>
<Paragraph position="43"> In general, it is clear that a word's combining potential (i.e., its comblnin E probabilities) may be affected by the syntactic environment in which it is placed. A generation program that does not take into account this possibility will be woefully inadequate. The problem is: which syntactic environments affect which words, and under which conditions? One use of the ASG program is to generate problems of this kind, and to test provisional solutions.</Paragraph>
<Paragraph position="44"> A second kind of syntactic problem arises when the grammatical number of nouns is inappropriate. (At present, the selection of number is made by the random number generator, operating on data in the grammar about the relative frequency of singular and plural in physics text.) Thus, in sentence (7) above, the combination &amp;quot;pri ras~etax&amp;quot; (&amp;quot;in calculations&amp;quot;) could have easily been generated, since the noun, &amp;quot;ras~et,&amp;quot; is frequently used in the plural. The strongly verbal nature of the noun in this environment, as noted above, makes the use of the singular noun almost imperative. (Deverbative nouns are almost never used in the plural when indicating a process.) The program should therefore be modified to require that a noun dependent of a sentence adverb be singular.</Paragraph>
<Paragraph position="45"> Two other instances of incorrect~umber in nouns may be mentioned.</Paragraph>
<Paragraph position="46"> Nouns of the general classification, &amp;quot;abstract collective,&amp;quot; require that genitive noun dependents be plural (unless the latter noun is rarely, or never, plural). Since the grammar contains no such specification, the~following ill-formed sentence was generated:  (9) Cislo ~to~o ~ otsutstvuet.</Paragraph>
<Paragraph position="47">  A number of this later is absent.</Paragraph>
<Paragraph position="48"> Other nouns (deverbatives), and their corresponding transitive verbs, appear to require that the noun complement be plural.</Paragraph>
<Paragraph position="49"> (I0) Izu~enie stolknovenij atom__~aopublikovano v predydus~e 3 rabote. A study of the collisions of an atom was published in a preceding paper.</Paragraph>
<Paragraph position="50"> The solution to the problem is to modify the grammar so that &amp;quot;collison,&amp;quot; will require the (subjective) genitive noun dependent in the plural. (A variation of this principle is '~ultiple complementation&amp;quot;: &amp;quot;the collision of an atom with (and) another atom.&amp;quot; Grammatical rules to account for this phenomenon are beyond the scope of the present grammar.) We conclude that there are no major syntactic problems in the sentences so far generated, chiefly because the grammar is relatively primitive.</Paragraph>
<Paragraph position="51"> Semantic problems are more difficult to isolate. Again, it is sometimes possible that the absence of appropriate context is the chief cause ofodd-soundinE sentences.</Paragraph>
<Paragraph position="52"> A trivial kind of error is caused by the inappropriate repetition</Paragraph>
<Paragraph position="54"> of a word: (ii) Analogi~naja formula i formula zaplsalis'. An analogous formula and a formula were written. It is easy to forbid the repetition of a word i~a sentence; such a restriction, however, would betoo severe (cf., for example, &amp;quot;We used formula i in deriving formula 2.&amp;quot;). In general, it appears that recurring words tend to be used in different clauses of the sentence. Until the program is capable of producing sentences of more than one clause, the best strategy is probably to forbid word repetition.</Paragraph>
<Paragraph position="55"> In some sentences, the choice of adjective modifier appears loglcally inconsistent, or incompatible.</Paragraph>
<Paragraph position="56"> (12) Molekuly detal'no izuceny, s cel'jura~_~ i~nerenija. The molecules were studied in detail, for the purpose of a different measuring.</Paragraph>
<Paragraph position="57"> The issue here is not the lack of a complement for '~easurlng,&amp;quot; but the use of &amp;quot;different&amp;quot; with the strongly verbal noun governor. In one sense, the difficulty &amp;quot;my be syntactic: &amp;quot;different&amp;quot; would in Russian normally be used with a plural noun, whereas a singular noun is strongly indicated in the present context. The oddity of the construction is, thus, partly the result of conflicting &amp;quot;forces&amp;quot; in the adjective and the noun.</Paragraph>
<Paragraph position="58"> Some sentences show the loss of meaning that may\ easily result from the expanslon 0f noun phrases by the addition of Ee~itive noun modifiers. null (13) Uravnenie zakonovra_~ada effekta pribli~eni~ pulucenl.</Paragraph>
<Paragraph position="59"> The equation of the laws of the decay of the effect of approxlmatlo_._.____n.nn is obtained.</Paragraph>
<Paragraph position="60"> The problem here is apparently the use of &amp;quot;effect&amp;quot; in two different phrases: &amp;quot;the decay of the (e.g., photoelastic) effect&amp;quot; is the kind of phrase found in physics texts, as is &amp;quot;the effect of approximating (e.g., the energy).&amp;quot; The confusion in (13) may be explained by the fact that the former expression refers to a physical phenomenon, whereas the latter refers to an exercise of the mind; the two incompatible phrases are forced together by the fact that &amp;quot;effect&amp;quot; is common to both. The anomaly may also be explained, more simply, by the different lexlcal properties of &amp;quot;effect.&amp;quot; A similar problem.my also arise in ers in a noun phrase. Thus, in the of adjectlve/noun,&amp;quot; varying degrees the adjectives: the use of two adjective modlflconstruction, &amp;quot;adjective/noun of fltness.my be observed for All (the) present ....</Paragraph>
<Paragraph position="61">  Should some of these combinations be forbidden? If so, on what basis? What is the effect of expanding the grammar so that conditional clauses (&amp;quot;if . . ., then . . .&amp;quot;) can be generated? One possibility is that adjectives can be semantically classified, so that logically incompatible combinations can be avoided. It is difficult to estimate whether or not such a path of investigation is fruitful.</Paragraph>
<Paragraph position="62"> At the present stage of research, problems of semantic &amp;quot;interference&amp;quot; have occurred infrequently. The generation of certain problem constructions is strongly indicated. For example, the program can be modified so as to produce, at a given point, one hundred sentences in which the construction, '~oun of noun of noun,&amp;quot; appears; likewise, it can be required that the second of the three nouns be a specific word (e.g., &amp;quot;effect&amp;quot;). From an examination of the output, we hope to gain some insight into the question of semantic compatibility.</Paragraph>
<Paragraph position="63"> A computer program for the automatic generation of sentences was written, based on a simplified dependency grammar for Russlan and a vocabulary of 550 words. Each word is provided a list of allowable constituents; the structure of a sentence is conditioned entirely by the lexical items chosen at each node in the dependency tree. Some of the generated sentences exhibit certain syntactic deficiencies (nouns are inadequately complemented or are given the wrong number); other problems result from the &amp;quot;interference&amp;quot; of. semantic fields beyond the context of the word-palr.</Paragraph>
</Section>
</Paper>

