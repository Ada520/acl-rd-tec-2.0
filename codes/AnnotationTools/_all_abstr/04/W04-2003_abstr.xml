<?xml version="1.0" standalone="yes"?>

<Paper uid="W04-2003">
<Title>A Robust and Hybrid Deep-Linguistic Theory Applied to Large-Scale Parsing</Title>
<Section position="1" start_page="0" end_page="0" type="abstr">
<SectionTitle>
Abstract
</SectionTitle>
<Paragraph position="0"> Modern statistical parsers are robust and quite fast, but their output is relatively shallow when compared to formal grammar parsers. We suggest to extend statistical approaches to a more deep-linguistic analysis while at the same time keeping the speed and low complexity of a statistical parser. The resulting parsing architecture suggested, implemented and evaluated here ishighlyrobustandhybridonanumberof levels, combining statistical and rule-based approaches, constituency and dependency grammar, shallow and deep processing, full and nearfull parsing. With its parsing speed of about 300,000 words per hour and state-of-the-art performance the parser is reliable for a number of large-scale applications discussed in the article.</Paragraph>
</Section>
</Paper>

