<?xml version="1.0" standalone="yes"?>

<Paper uid="J92-3001">
<Title>Making DATR Work for Speech: Lexicon Compilation in SUNDIAL</Title>
<Section position="2" start_page="0" end_page="247" type="abstr">
<SectionTitle>
1. Introduction
</SectionTitle>
<Paragraph position="0"> In this paper we describe DIALEX, a modular inheritance-based tool for the construction of lexicalized grammar knowledge bases. DIALEX has been developed as part of the SUNDIAL (Speech UNderstanding and DIALogue) project--currently one of Europe's largest collaborative research projects in speech and language technology, l SUNDIAL's main project goal is to produce four prototype systems that support relatively unconstrained telephone dialogs for limited domains in each of English, French, German, and Italian (Peckham 1991). This paper reports work carried out in the devel- null opment of the English and French systems. These share a common application domain, namely flight enquiries and reservations.</Paragraph>
<Paragraph position="1"> * Cap Gemini Innovation, 118 Rue de Tocqueville, 75017 Paris, France (andry@capsogeti.fr). t Social and Computer Sciences Research Group, University of Surrey, Guildford, Surrey, GU2 5XH, U.K. (norman@soc.surrey.ac.uk; scott@soc.surrey.ac.uk). :~ Logica Cambridge Ltd, Betjeman House, 104 Hills Road, Cambridge, CB2 1LQ, U.K. (simont@logcam.co.uk; nick@logcam.co.uk). 1 The work reported here was supported in part by the Commission of the European Communities as part of ESPRIT project P2218, SUNDIAL. Partners in the project are Cap Gemini Innovation, CNET, IRISA (France); Daimler-Benz, Siemens, University of Erlangen (Germany); CSELT, Saritel (Italy); Logica Cambridge Ltd, University of Surrey (U.K). We acknowledge with gratitude the helpful comments and suggestions of the editors and reviewers of this special issue of Computational Linguistics and of Lionel Moser. (~) 1992 Association for Computational Linguistics  Computational Linguistics Volume 18, Number 3 The process of writing linguistic knowledge bases has been guided by a number of design requirements on the SUNDIAL project as a whole.</Paragraph>
<Paragraph position="3"> First of all, prototype systems must be capable of understanding speech.</Paragraph>
<Paragraph position="4"> Therefore grammars must be appropriate for the purposes of speech processing. For example, they must reflect the fact that input to the parser is a word lattice or graph from which some of the spoken words (typically short words such as function words) may be missing.</Paragraph>
<Paragraph position="5"> Each prototype system must be capable of producing speech. Speech generation takes place in two stages. In the first stage, text is generated. In the second stage, a text-to-speech system outputs the message.</Paragraph>
<Paragraph position="6"> Therefore the linguistic knowledge must also be structured appropriately for the purposes of text generation.</Paragraph>
<Paragraph position="7"> Each system must run in real time or near real time. Therefore the linguistic knowledge must be structured so as to allow rapid access and manipulation.</Paragraph>
<Paragraph position="8"> Portability to new applications should be simple; work required to write new linguistic knowledge bases should therefore be kept to a minimum. Duplication of effort must be avoided. This must be true in respect of the components of each separate prototype system. For example, the same dialog manager software module has been used in each prototype with minor customizations for each language (Bilange 1991; McGlashan et al.</Paragraph>
<Paragraph position="9"> 1992). The same principle should apply to the design of tools for the construction of knowledge bases, including lexical knowledge bases.</Paragraph>
<Paragraph position="10"> Thus, the task of adding a new lexical item should only require the addition of knowledge that is idiosyncratic to that lexical item and not predictable from what is already present in the knowledge base.</Paragraph>
<Paragraph position="11"> Section 2 of this paper presents an overview of the SUNDIAL DIALEX tool. Section 3 describes the way in which linguistic knowledge is initially expressed in terms of declarative DATR theories. Section 4 explains how a compact DATR knowledge base is expanded out into a fully specified lexicon. Section 5 relates how the lexicon can be customized for the purposes of real-time speech parsing. Practical experiences of constructing and using DIALEX are recounted in Section 6. Concluding observations are drawn in Section 7.</Paragraph>
<Paragraph position="12"> 2. Overview of the System In common with contemporary generative theories that are unification based and for which information is concentrated in the lexicon (Pollard and Sag 1987; Calder et al. 1988), we adopt the sign as our basic unit of linguistic representation. For a given lexical entry, a sign describes the constraints--morphological, syntactic, and semantic--it  Francois Andry et al. Making DATR Work for Speech introduces. The sign for intransitive arrives, for example, is:</Paragraph>
<Paragraph position="14"> The lexical sign for arrives combines syntactic head features that help to determine the inflected form, with an args list that constrains its environment within the phrase of which it is the head; the sere feature represents the semantic structure that will be assigned to that phrase. The sign shows that the verb may optionally be followed by a prepositional phrase whose semantics will fill the semantic role thetime. 2 The argument preceding the verb is constrained to be third person singular nominative (i.e. not object-marked), and supplies the filler for the semantic role theagent.</Paragraph>
<Paragraph position="15"> In the interests of linguistic parsimony and sensible knowledge engineering, it is necessary for lexicalist approaches to factor away at the lexicon-encoding interface as many as possible of the commonalities between lexical items. To this end, we adopt the principles of default inheritance (Gazdar 1987), as embodied in the DATR language (Evans and Gazdar 1989). Areas where abstractions may be made over the lexicon are morphosyntax (Gazdar 1990), transitivity (Charniak and McDermott 1985; Flickinger et al. 1985; Hudson 1990), and combinations of these leading to lexical rules such as passive. To this we have added the area of lexico-semantic relations. In order to generalize over semantic roles, it is necessary to tie these to functional-syntactic roles, such as subject, direct object, etc. These in turn are related to order marked arguments in the args frame. Only the latter appear in the final version of the lexicon.</Paragraph>
<Paragraph position="16"> 2 In our representation of feature structures we follow Prolog conventions, whereby variables are identified by initial capitals, and a vertical bar introduces the tail of a list.</Paragraph>
<Paragraph position="17">  Computational Linguistics Volume 18, Number 3 A major issue for approaches such as ours is whether or not regularities in the lexicon should be expanded out off-line, or remain for lazy evaluation during parsing. We are sympathetic with the latter approach, for reasons of the economies that can be achieved in lexicon size. However, we believe that a precompiled lexicon is more appropriate to current speech recognition technology. Parsing typically involves extremely large lattices of lexical hypotheses with imprecise boundaries, and is thus computationally expensive. Our experience suggests that the trade-off between lexicon size and the cost of online inference is such as to favor lexicon size, in the case of application-specific lexicons of the size required in the SUNDIAL systems (around 2000 words). For inflection-impoverished English and (somewhat richer) French, which form the basis of our work, limited morphological decomposition during parsing is avoided; instead the parser lexicon consists of fully inflected forms.</Paragraph>
<Paragraph position="18"> The parser lexicon we have developed has the following two properties.</Paragraph>
<Paragraph position="19"> .</Paragraph>
<Paragraph position="20"> .</Paragraph>
<Paragraph position="21"> It is indexed by surface forms, i.e. fully inflected words that are unique at the phonological level. Efficiency of access is achieved by allowing some internal disjunctions within entries in cases where the surface form can be derived from a number of morphosyntactic feature combinations.</Paragraph>
<Paragraph position="22"> It consists of two separate knowledge bases: an acceptance lexicon and a full lexicon. The former is designed for efficient parsing. Only those features that constrain the ability of a sign to combine are represented.</Paragraph>
<Paragraph position="23"> These include syntactic head features and semantic types. The encoding technique uses bit-vectors to achieve economy of representation and fast unification. The full lexicon contains signs with no information missing; the information in a full lexical entry is therefore a superset of the corresponding acceptance lexicon entry.</Paragraph>
<Paragraph position="24"> Parsing takes place in two phases: lattice parsing using the acceptance lexicon, involving heuristic search with intensive computation; and structure building, which operates on the analysis tree produced by the first phase, using term unification to combine the entries from the full lexicon corresponding to the lexical entries found by the first phase.</Paragraph>
<Paragraph position="25"> The lexicon compilation architecture that we present in this paper is outlined in Figure 1.</Paragraph>
<Paragraph position="26"> At the lexical encoding interface, a human lexicon builder builds an applicationand sublanguage-specific lexicon, using a set of structured base definitions, which generalize over commonalities and provide macros with which to structure entries (Section 3). Both of these are written in DATR; we refer to the output of this as the DATR lexicon. The lexicon generator then compiles this into a lexicon for which the entries are directed acyclic graphs (DAGs) indexed by surface forms. For this a set of closure definitions is used. These constitute a knowledge base forming a set of meta-definitions to complement the DATR lexicon, as well as rendering explicit what may be implicit in the latter (Section 4). The resulting entries are encoded in two ways: for the full lexicon via Prolog term encoding and for the acceptance lexicon via bit coding (Section 5).</Paragraph>
</Section>
</Paper>

